{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dg chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.0.0\n",
      "alabaster==0.7.12\n",
      "anyio==3.5.0\n",
      "apex==0.1\n",
      "appdirs==1.4.4\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\n",
      "attrs==18.2.0\n",
      "audioread==2.1.9\n",
      "Babel==2.9.1\n",
      "backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n",
      "backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n",
      "beautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1631087867185/work\n",
      "black @ file:///home/conda/feedstock_root/build_artifacts/black-recipe_1643636307408/work\n",
      "bleach==4.1.0\n",
      "blis @ file:///home/conda/feedstock_root/build_artifacts/cython-blis_1636053204017/work\n",
      "brotlipy @ file:///home/conda/feedstock_root/build_artifacts/brotlipy_1636012188166/work\n",
      "cachetools==5.0.0\n",
      "catalogue @ file:///home/conda/feedstock_root/build_artifacts/catalogue_1638867392804/work\n",
      "certifi==2021.10.8\n",
      "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1636046063618/work\n",
      "chardet @ file:///home/conda/feedstock_root/build_artifacts/chardet_1635814844635/work\n",
      "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1638815705608/work\n",
      "click @ file:///home/conda/feedstock_root/build_artifacts/click_1635822600067/work\n",
      "click-completion==0.5.2\n",
      "click-didyoumean==0.3.0\n",
      "click-help-colors==0.9.1\n",
      "cloudpickle==2.0.0\n",
      "codecov==2.1.12\n",
      "colorama==0.4.3\n",
      "conda==4.11.0\n",
      "conda-build==3.21.8\n",
      "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1636021700973/work\n",
      "coverage==6.3.1\n",
      "cryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography_1639699280509/work\n",
      "cudf @ file:///rapids/cudf-21.12.0a0%2B293.g0930f712e6-cp38-cp38-linux_x86_64.whl\n",
      "cugraph @ file:///rapids/cugraph-21.12.0a0%2B95.g4b8c1330-cp38-cp38-linux_x86_64.whl\n",
      "cuml @ file:///rapids/cuml-21.12.0a0%2B116.g4ce5bd609-cp38-cp38-linux_x86_64.whl\n",
      "cupy-cuda115 @ file:///rapids/cupy_cuda115-9.6.0-cp38-cp38-manylinux1_x86_64.whl\n",
      "cycler==0.11.0\n",
      "cymem @ file:///home/conda/feedstock_root/build_artifacts/cymem_1636053152744/work\n",
      "Cython==0.29.27\n",
      "dask @ file:///rapids/dask-2021.11.2-py3-none-any.whl\n",
      "dask-cuda @ file:///rapids/dask_cuda-21.12.0-py3-none-any.whl\n",
      "dask-cudf @ file:///rapids/dask_cudf-21.12.0a0%2B293.g0930f712e6-py3-none-any.whl\n",
      "dataclasses @ file:///home/conda/feedstock_root/build_artifacts/dataclasses_1628958434797/work\n",
      "debugpy==1.5.1\n",
      "decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n",
      "defusedxml==0.7.1\n",
      "distributed @ file:///rapids/distributed-2021.11.2-py3-none-any.whl\n",
      "docutils==0.17.1\n",
      "entrypoints==0.3\n",
      "executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1633213722787/work\n",
      "expecttest==0.1.3\n",
      "fastrlock==0.8\n",
      "filelock @ file:///home/conda/feedstock_root/build_artifacts/filelock_1641470428964/work\n",
      "flake8==3.7.9\n",
      "Flask==2.0.3\n",
      "fonttools==4.29.1\n",
      "fsspec==2022.1.0\n",
      "future==0.18.2\n",
      "glob2==0.7\n",
      "google-auth==2.6.0\n",
      "google-auth-oauthlib==0.4.6\n",
      "gql==3.0.0a6\n",
      "gradient==1.10.0\n",
      "gradient-utils==0.5.0\n",
      "graphql-core==3.1.7\n",
      "graphsurgeon @ file:///workspace/TensorRT-8.2.3.0/graphsurgeon/graphsurgeon-0.4.5-py2.py3-none-any.whl\n",
      "grpcio==1.43.0\n",
      "halo==0.0.31\n",
      "HeapDict==1.0.1\n",
      "hypothesis==4.50.8\n",
      "idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1609836280497/work\n",
      "imagesize==1.3.0\n",
      "importlib-metadata==4.11.1\n",
      "importlib-resources==5.4.0\n",
      "iniconfig==1.1.1\n",
      "ipykernel==6.9.0\n",
      "ipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1642613634924/work\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.7.0\n",
      "itsdangerous==2.0.1\n",
      "jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1637175084646/work\n",
      "Jinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1636510082894/work\n",
      "joblib==1.1.0\n",
      "json5==0.9.6\n",
      "jsonschema==4.4.0\n",
      "jupyter-client==7.1.2\n",
      "jupyter-core==4.9.1\n",
      "jupyter-server==1.15.6\n",
      "jupyter-tensorboard @ git+https://github.com/cliffwoolley/jupyter_tensorboard.git@ffa7e26138b82549453306e06b535a9ac36db17a\n",
      "jupyterlab==3.3.2\n",
      "jupyterlab-pygments==0.1.2\n",
      "jupyterlab-server==2.11.2\n",
      "jupyterlab-widgets==1.1.0\n",
      "jupytext==1.13.7\n",
      "kiwisolver==1.3.2\n",
      "langcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1636741340529/work\n",
      "libarchive-c @ file:///home/conda/feedstock_root/build_artifacts/python-libarchive-c_1643045750800/work\n",
      "librosa==0.9.0\n",
      "llvmlite==0.36.0\n",
      "lmdb==1.3.0\n",
      "locket==0.2.1\n",
      "log-symbols==0.0.14\n",
      "Markdown==3.3.6\n",
      "markdown-it-py==1.1.0\n",
      "MarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1635833572614/work\n",
      "marshmallow==2.21.0\n",
      "matplotlib==3.5.1\n",
      "matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\n",
      "mccabe==0.6.1\n",
      "mdit-py-plugins==0.3.0\n",
      "mistune==0.8.4\n",
      "mock @ file:///home/conda/feedstock_root/build_artifacts/mock_1635819534735/work\n",
      "msgpack==1.0.3\n",
      "multidict==6.0.2\n",
      "murmurhash @ file:///home/conda/feedstock_root/build_artifacts/murmurhash_1636019583024/work\n",
      "mypy-extensions @ file:///home/conda/feedstock_root/build_artifacts/mypy_extensions_1635839660470/work\n",
      "nbclassic==0.3.7\n",
      "nbclient==0.5.11\n",
      "nbconvert==6.4.2\n",
      "nbformat==5.2.0\n",
      "nest-asyncio==1.5.4\n",
      "networkx==2.6.3\n",
      "nltk==3.7\n",
      "notebook==6.4.1\n",
      "notebook-shim==0.1.0\n",
      "numba @ file:///home/conda/feedstock_root/build_artifacts/numba_1623568544775/work\n",
      "numpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1643958805350/work\n",
      "nvidia-dali-cuda110==1.10.0\n",
      "nvidia-pyindex==1.0.9\n",
      "nvtx==0.2.4\n",
      "oauthlib==3.2.0\n",
      "onnx @ file:///opt/pytorch/pytorch/third_party/onnx\n",
      "packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\n",
      "pandas==1.3.5\n",
      "pandocfilters==1.5.0\n",
      "parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\n",
      "partd==1.2.0\n",
      "pathspec @ file:///home/conda/feedstock_root/build_artifacts/pathspec_1626613672358/work\n",
      "pathy @ file:///home/conda/feedstock_root/build_artifacts/pathy_1635227809952/work\n",
      "pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\n",
      "pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n",
      "Pillow @ file:///tmp/pillow-simd\n",
      "pkginfo @ file:///home/conda/feedstock_root/build_artifacts/pkginfo_1638813452194/work\n",
      "platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1644222440849/work\n",
      "pluggy==1.0.0\n",
      "polygraphy==0.33.0\n",
      "pooch==1.6.0\n",
      "preshed @ file:///home/conda/feedstock_root/build_artifacts/preshed_1636077712344/work\n",
      "prettytable==3.1.0\n",
      "progressbar2==4.0.0\n",
      "prometheus-client==0.9.0\n",
      "prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1643362612956/work\n",
      "protobuf==3.19.4\n",
      "psutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1640887117172/work\n",
      "ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n",
      "py==1.11.0\n",
      "pyarrow @ file:///rapids/pyarrow-5.0.0-cp38-cp38-linux_x86_64.whl\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pybind11==2.9.1\n",
      "pycocotools @ git+https://github.com/nvidia/cocoapi.git@142b17a358fdb5a31f9d5153d7a9f3f1cd385178#subdirectory=PythonAPI\n",
      "pycodestyle==2.5.0\n",
      "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1636020377748/work\n",
      "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
      "pydantic @ file:///home/conda/feedstock_root/build_artifacts/pydantic_1636021149719/work\n",
      "pydot==1.4.2\n",
      "pyflakes==2.1.1\n",
      "Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1641580240686/work\n",
      "pymongo==3.12.3\n",
      "pynvml==11.4.1\n",
      "pyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1633192417276/work\n",
      "pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1642753572664/work\n",
      "pyrsistent==0.18.1\n",
      "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1635862404924/work\n",
      "pytest==6.2.5\n",
      "pytest-cov==3.0.0\n",
      "pytest-pythonpath==0.7.4\n",
      "python-dateutil==2.8.2\n",
      "python-hostlist==1.21\n",
      "python-nvd3==0.15.0\n",
      "python-slugify==5.0.2\n",
      "python-utils==3.1.0\n",
      "pytorch-quantization==2.1.2\n",
      "pytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1633452062248/work\n",
      "PyYAML==5.4.1\n",
      "pyzmq==22.3.0\n",
      "regex==2022.1.18\n",
      "requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1637771257551/work\n",
      "requests-oauthlib==1.3.1\n",
      "requests-toolbelt==0.9.1\n",
      "resampy==0.2.2\n",
      "revtok @ git+git://github.com/jekbradbury/revtok.git@f1998b72a941d1e5f9578a66dc1c20b01913caab\n",
      "rmm @ file:///rapids/rmm-21.12.0a0%2B31.g0acbd51-cp38-cp38-linux_x86_64.whl\n",
      "rsa==4.8\n",
      "ruamel-yaml-conda @ file:///home/conda/feedstock_root/build_artifacts/ruamel_yaml_1636009157217/work\n",
      "sacremoses==0.0.47\n",
      "scikit-learn @ file:///rapids/scikit_learn-0.24.0-cp38-cp38-manylinux2010_x86_64.whl\n",
      "scipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1619561901336/work\n",
      "Send2Trash==1.8.0\n",
      "shellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1612179560728/work\n",
      "six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n",
      "smart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_1630238320325/work\n",
      "sniffio==1.2.0\n",
      "snowballstemmer==2.2.0\n",
      "sortedcontainers==2.4.0\n",
      "SoundFile==0.10.3.post1\n",
      "soupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1638550740809/work\n",
      "spacy @ file:///home/conda/feedstock_root/build_artifacts/spacy_1642167419405/work\n",
      "spacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1625687473390/work\n",
      "spacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1634809367310/work\n",
      "Sphinx==4.4.0\n",
      "sphinx-glpi-theme==0.3\n",
      "sphinx-rtd-theme==1.0.0\n",
      "sphinxcontrib-applehelp==1.0.2\n",
      "sphinxcontrib-devhelp==1.0.2\n",
      "sphinxcontrib-htmlhelp==2.0.0\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.3\n",
      "sphinxcontrib-serializinghtml==1.1.5\n",
      "spinners==0.0.24\n",
      "srsly @ file:///home/conda/feedstock_root/build_artifacts/srsly_1638879568141/work\n",
      "stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1642255706390/work\n",
      "tabulate==0.8.9\n",
      "tblib==1.7.0\n",
      "tensorboard==2.8.0\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorrt @ file:///workspace/TensorRT-8.2.3.0/python/tensorrt-8.2.3.0-cp38-none-linux_x86_64.whl\n",
      "termcolor==1.1.0\n",
      "terminado==0.13.1\n",
      "terminaltables==3.1.10\n",
      "testpath==0.5.0\n",
      "text-unidecode==1.3\n",
      "thinc @ file:///home/conda/feedstock_root/build_artifacts/thinc_1638980259098/work\n",
      "threadpoolctl==3.1.0\n",
      "toml==0.10.2\n",
      "tomli @ file:///home/conda/feedstock_root/build_artifacts/tomli_1644342247877/work\n",
      "toolz==0.11.2\n",
      "torch==1.11.0a0+17540c5\n",
      "torch-tensorrt @ file:///opt/pytorch/torch_tensorrt/py/dist/torch_tensorrt-1.1.0a0-cp38-cp38-linux_x86_64.whl\n",
      "torchtext @ file:///opt/pytorch/text\n",
      "torchvision @ file:///opt/pytorch/vision\n",
      "tornado==6.1\n",
      "tqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1632160078689/work\n",
      "traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1635260543454/work\n",
      "treelite @ file:///rapids/treelite-2.1.0-py3-none-manylinux2014_x86_64.whl\n",
      "treelite-runtime @ file:///rapids/treelite_runtime-2.1.0-py3-none-manylinux2014_x86_64.whl\n",
      "typed-ast @ file:///home/conda/feedstock_root/build_artifacts/typed-ast_1643045767561/work\n",
      "typer @ file:///home/conda/feedstock_root/build_artifacts/typer_1630326630489/work\n",
      "typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1638334978229/work\n",
      "ucx-py @ file:///rapids/ucx_py-0.21.0a0%2B37.gbfa0450-cp38-cp38-linux_x86_64.whl\n",
      "uff @ file:///workspace/TensorRT-8.2.3.0/uff/uff-0.6.9-py2.py3-none-any.whl\n",
      "urllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1632350318291/work\n",
      "wasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1638865582891/work\n",
      "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n",
      "webencodings==0.5.1\n",
      "websocket-client==0.57.0\n",
      "Werkzeug==2.0.3\n",
      "wget==3.2\n",
      "widgetsnbextension==3.6.0\n",
      "xgboost @ file:///rapids/xgboost-1.5.0-cp38-cp38-linux_x86_64.whl\n",
      "yarl==1.7.2\n",
      "zict==2.0.0\n",
      "zipp==3.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ds9xP7rtnrZ"
   },
   "source": [
    "Next, change directory to wherever you created your folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 28 00:27:49 UTC 2022\n",
      "/notebooks/ml639a/639c\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FkyXFsLGtvyc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/ml639a/639c\n",
      "/notebooks/ml639a/639c\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import os\n",
    "\n",
    "# TODO: Change this to your Drive folder location\n",
    "WORKING_DIRECTORY = '/home/studio-lab-user/ml635e/ir'\n",
    "WORKING_DIRECTORY = '/notebooks/ml639a/639c'\n",
    "imgdir='/notebooks/imgdata/inrm4pyt'\n",
    "imgtrain = '/notebooks/imgdata/inrm4pyt/train'\n",
    "imgval = '/notebooks/imgdata/inrm4pyt/val'\n",
    "\n",
    "os.chdir(WORKING_DIRECTORY)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1654738344918,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "nNbnk4pitjF0",
    "outputId": "a9ad9d39-1104-4098-fda5-f31c570f58be",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.639.ir.ipynb\n"
     ]
    }
   ],
   "source": [
    "# List the contents of your working directory\n",
    "# It should contain at least three folders: images, train_labels, and val_labels\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43sPuLgxuemn"
   },
   "source": [
    "Now, let's install the Detecto package using pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3427,
     "status": "ok",
     "timestamp": 1654738351538,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "M3-sRIuiuYDh",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b97165ba-2a42-4df2-8c2d-982be162c3fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting detecto\n",
      "  Downloading detecto-1.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from detecto) (4.62.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from detecto) (3.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from detecto) (1.3.5)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.9 MB 20.9 MB/s eta 0:00:01    |███████▌                        | 14.3 MB 757 kB/s eta 0:01:02\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from detecto) (1.11.0a0+17540c5)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from detecto) (0.12.0a0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (1.22.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detecto) (4.29.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->detecto) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->detecto) (2021.3)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->detecto) (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->detecto) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->detecto) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->detecto) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->detecto) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->detecto) (2.0.9)\n",
      "Installing collected packages: opencv-python, detecto\n",
      "Successfully installed detecto-1.2.2 opencv-python-4.6.0.66\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Note: if it states you must restart the runtime in order to use a\n",
    "# newly installed version of a package, you do NOT need to do this. \n",
    "!pip install detecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peLysju5vOgA"
   },
   "source": [
    "Import everything we need in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Fetched 222 kB in 1s (263 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "55 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "python3-opencv is already the newest version (4.2.0+dfsg-5).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 55 not upgraded.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.22.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt update\n",
    "DEBIAN_FRONTEND=noninteractive apt-get install -y python3-opencv\n",
    "#tz prompt. dpkg fix...\n",
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "id": "XgJi8407uowH",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'cv2' has no attribute 'gapi_wip_gst_GStreamerPipeline' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetecto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core, utils, visualize\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detecto/core.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetecto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetecto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_transforms, filter_top_predictions, xml_to_csv, _is_iterable, read_image\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfaster_rcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastRCNNPredictor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detecto/utils.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/cv2/__init__.py:181\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/cv2/__init__.py:175\u001b[0m, in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: binary extension... OK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submodule \u001b[38;5;129;01min\u001b[39;00m __collect_extra_submodules(DEBUG):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m__load_extra_py_code_for_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/cv2/__init__.py:28\u001b[0m, in \u001b[0;36m__load_extra_py_code_for_module\u001b[0;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[1;32m     26\u001b[0m native_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(module_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     py_module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m enable_debug_print:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/cv2/gapi/__init__.py:290\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel_with_params\n\u001b[0;32m--> 290\u001b[0m cv\u001b[38;5;241m.\u001b[39mgapi\u001b[38;5;241m.\u001b[39mwip\u001b[38;5;241m.\u001b[39mGStreamerPipeline \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgapi_wip_gst_GStreamerPipeline\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'cv2' has no attribute 'gapi_wip_gst_GStreamerPipeline' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from detecto import core, utils, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5UqkoIevXSX"
   },
   "source": [
    "To check that everything's working, we can try reading in one of the images from our images folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "execution": {
     "iopub.execute_input": "2022-06-11T18:02:07.318589Z",
     "iopub.status.busy": "2022-06-11T18:02:07.318189Z",
     "iopub.status.idle": "2022-06-11T18:02:07.841871Z",
     "shell.execute_reply": "2022-06-11T18:02:07.840886Z",
     "shell.execute_reply.started": "2022-06-11T18:02:07.318549Z"
    },
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1654738365701,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "FmjpizSMvJLn",
    "outputId": "d514d7dc-8752-4832-adbd-741915861fc0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = utils.read_image('images/inner_rim_210805T104053.png')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCEC_0EQwLDf"
   },
   "source": [
    "How cute! Now, we're ready to create our dataset and train our model. However, before doing so, it's a bit slow working with hundreds of individual XML label files, so we should convert them into a single CSV file to save time later down the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 12135,
     "status": "ok",
     "timestamp": 1654738743456,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "_Pnr8quRv8v7",
    "outputId": "53a5f852-6dbe-4e3f-c754-6ea474f9bb2a",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Do this twice: once for our trning labels and once for our validation labels\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# /notebooks/imgdata/inrm4pyt/train.csv\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mxml_to_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/imgdata/inrm4pyt/train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "# Do this twice: once for our trning labels and once for our validation labels\n",
    "# /notebooks/imgdata/inrm4pyt/train.csv\n",
    "utils.xml_to_csv('/notebooks/imgdata/inrm4pyt/train', 'train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2022-06-11T18:02:14.380155Z",
     "iopub.status.busy": "2022-06-11T18:02:14.379766Z",
     "iopub.status.idle": "2022-06-11T18:02:14.772255Z",
     "shell.execute_reply": "2022-06-11T18:02:14.771194Z",
     "shell.execute_reply.started": "2022-06-11T18:02:14.380117Z"
    },
    "executionInfo": {
     "elapsed": 12135,
     "status": "ok",
     "timestamp": 1654738743456,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "_Pnr8quRv8v7",
    "outputId": "53a5f852-6dbe-4e3f-c754-6ea474f9bb2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inner_rim_210805T104131.png</td>\n",
       "      <td>260</td>\n",
       "      <td>7990</td>\n",
       "      <td>Chip</td>\n",
       "      <td>1</td>\n",
       "      <td>1364</td>\n",
       "      <td>191</td>\n",
       "      <td>1694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inner_rim_210805T104053.png</td>\n",
       "      <td>260</td>\n",
       "      <td>7990</td>\n",
       "      <td>Chip</td>\n",
       "      <td>2</td>\n",
       "      <td>4899</td>\n",
       "      <td>192</td>\n",
       "      <td>5231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inner_rim_210805T104112.png</td>\n",
       "      <td>260</td>\n",
       "      <td>7990</td>\n",
       "      <td>Chip</td>\n",
       "      <td>1</td>\n",
       "      <td>4013</td>\n",
       "      <td>192</td>\n",
       "      <td>4332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  width  height class  xmin  ymin  xmax  ymax  \\\n",
       "0  inner_rim_210805T104131.png    260    7990  Chip     1  1364   191  1694   \n",
       "1  inner_rim_210805T104053.png    260    7990  Chip     2  4899   192  5231   \n",
       "2  inner_rim_210805T104112.png    260    7990  Chip     1  4013   192  4332   \n",
       "\n",
       "   image_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.xml_to_csv('val', 'val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csLF8GKQ3CGe"
   },
   "source": [
    "Below, we create our dataset, applying a couple of transforms beforehand. These are optional, but they can be useful for augmenting your dataset without gathering more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1654741423315,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "m7j17jxf31Gk",
    "outputId": "2f47347d-66ca-485b-f655-216806d8ae4c",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'core' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Specify a list of transformations for our dataset to apply on our images\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# transform_img = transforms.Compose([\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     transforms.ToPILImage(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     utils.normalize_transform(),\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ])\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/imgdata/inrm4pyt/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/imgdata/inrm4pyt/images/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# dataset[i] returns a tuple containing our transformed image and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# and a dictionary containing label and box data\u001b[39;00m\n\u001b[1;32m     14\u001b[0m image, target \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'core' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify a list of transformations for our dataset to apply on our images\n",
    "# transform_img = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize(800),\n",
    "#     transforms.RandomHorizontalFlip(0.5),\n",
    "#     transforms.ToTensor(),\n",
    "#     utils.normalize_transform(),\n",
    "# ])\n",
    "\n",
    "dataset = core.Dataset('/notebooks/imgdata/inrm4pyt/train.csv', '/notebooks/imgdata/inrm4pyt/images/')\n",
    "\n",
    "# dataset[i] returns a tuple containing our transformed image and\n",
    "# and a dictionary containing label and box data\n",
    "image, target = dataset[0]\n",
    "\n",
    "# Show our image along with the box. Note: it may\n",
    "# be colored oddly due to being normalized by the \n",
    "# dataset and then reverse-normalized for plotting\n",
    "visualize.show_labeled_image(image, target['boxes'], target['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPFYk-lv6Cgd"
   },
   "source": [
    "Finally, let's train our model! First, we create a DataLoader over our dataset to specify how we feed the images into our model. We also use our validation dataset to track the accuracy of the model throughout training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "execution": {
     "iopub.execute_input": "2022-06-11T18:02:39.009318Z",
     "iopub.status.busy": "2022-06-11T18:02:39.008996Z",
     "iopub.status.idle": "2022-06-11T18:02:58.431964Z",
     "shell.execute_reply": "2022-06-11T18:02:58.429644Z",
     "shell.execute_reply.started": "2022-06-11T18:02:39.009289Z"
    },
    "executionInfo": {
     "elapsed": 50319,
     "status": "error",
     "timestamp": 1654741490003,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "WLRHugVo6kAt",
    "outputId": "a9c7a102-cfe6-40eb-ed6e-64d5a0e3c02d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e166fd8f627c4f77ae5219eb429948be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/160M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 3\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/1923109836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train the model! This step can take a while, so make sure you\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# the GPU is turned on in Edit -> Notebook settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Plot the accuracy over time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detecto/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, val_dataset, epochs, learning_rate, momentum, weight_decay, gamma, lr_step_size, verbose)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0;31m# Calculate the model's loss (i.e. how well it does on the current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0;31m# image and target, with a lower loss being better)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                 \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mmatched_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0mbox_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_roi_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0mbox_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mclass_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_regression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, boxes, image_shapes)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_roi_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscales\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_scales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36msetup_scales\u001b[0;34m(self, features, image_shapes)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0moriginal_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_input_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# get the levels in the feature map by leveraging the fact that the network always\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# downsamples by a factor of 2 at each level.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0moriginal_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_input_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# get the levels in the feature map by leveraging the fact that the network always\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# downsamples by a factor of 2 at each level.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36minfer_scale\u001b[0;34m(self, feature, original_size)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mpossible_scales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mpossible_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpossible_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpossible_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create our validation dataset\n",
    "val_dataset = core.Dataset('/notebooks/imgdata/inrm4pyt/val.csv', '/notebooks/imgdata/inrm4pyt/images/')\n",
    "\n",
    "# Create the loader for our training dataset\n",
    "loader = core.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Create our model, passing in all unique classes we're predicting\n",
    "# Note: make sure these match exactly with the labels in the XML/CSV files!\n",
    "model = core.Model(['Chip'])\n",
    "\n",
    "# Train the model! This step can take a while, so make sure you\n",
    "# the GPU is turned on in Edit -> Notebook settings\n",
    "losses = model.fit(loader, val_dataset, epochs=3, verbose=True)\n",
    "\n",
    "# Plot the accuracy over time\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeRKZMNJ9cfc"
   },
   "source": [
    "Let's see how well our model does on a couple images from our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-06-10T02:00:56.683685Z",
     "iopub.status.busy": "2022-06-10T02:00:56.682735Z",
     "iopub.status.idle": "2022-06-10T02:00:56.833569Z",
     "shell.execute_reply": "2022-06-10T02:00:56.832122Z",
     "shell.execute_reply.started": "2022-06-10T02:00:56.683630Z"
    },
    "executionInfo": {
     "elapsed": 3480,
     "status": "ok",
     "timestamp": 1654739642859,
     "user": {
      "displayName": "David Gleba",
      "userId": "15493013878878444265"
     },
     "user_tz": 240
    },
    "id": "rvHbAcLb9cIL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b3187aa0-913e-49f5-e767-858387ef12e6"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grid dimensions do not match size of list of images",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2999/2043643731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot a  grid of the model's predictions on our  images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_prediction_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detecto/visualize.py\u001b[0m in \u001b[0;36mplot_prediction_grid\u001b[0;34m(model, images, dim, figsize, score_filter)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Grid dimensions do not match size of list of images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Grid dimensions do not match size of list of images"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "# Create a list of images  from val_dataset\n",
    "for i in range(0, 2, 1):\n",
    "    image, _ = val_dataset[i]\n",
    "    images.append(image)\n",
    "\n",
    "# Plot a  grid of the model's predictions on our  images\n",
    "visualize.plot_prediction_grid(model, images, dim=(1, 3), figsize=(33, 33))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDz1v5Lh-uZG"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Thanks for making it this far through the demo!\n",
    "\n",
    "This is as far as the demo goes, but a great next step would be seeing how well the model works on a live video of Chihuahuas and Golden Retrievers in the same frame at the same time. To learn more about Detecto, be sure to check out the [Quickstart guide](https://detecto.readthedocs.io/en/latest/usage/quickstart.html), [Further Usage guide](https://detecto.readthedocs.io/en/latest/usage/further-usage.html), and [API docs](https://detecto.readthedocs.io/en/latest/api.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PgWhg2B0XhK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "detecto-dg01.ipynb",
   "provenance": [
    {
     "file_id": "1ISaTV5F-7b4i2QqtjTa7ToDPQ2k8qEe0",
     "timestamp": 1654741560702
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
