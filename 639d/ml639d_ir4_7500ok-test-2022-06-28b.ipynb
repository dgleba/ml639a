{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FINE TUNING FASTER RCNN USING PYTORCH**\n",
    "\n",
    "ir4 tester \n",
    "\n",
    "In this Notebook we can fine tune a Faster RCNN on the images dataset. If you want to brush up about what is Faster RCNN, [here's](https://medium.com/@whatdhack/a-deeper-look-at-how-faster-rcnn-works-84081284e1cd) an awesome medium article on the same.\n",
    "\n",
    "Ref: inspired by the Pytorch docs tutorial [here](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a lot of code for object detection is same and has to be rewritten by everyone, torchvision contributers have provided us with helper codes for training, evaluation and transformations.\n",
    "\n",
    "Let's clone the repo and copy the libraries into working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/ml639a/639d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'vision' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/ml639a/639d\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "# Download TorchVision repo to use some files from references/detection\n",
    "cd /notebooks\n",
    "mkdir -p pytorchvision\n",
    "cd pytorchvision\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "##!git checkout v0.3.0\n",
    "cp vision/references/detection/utils.py ./\n",
    "cp vision/references/detection/transforms.py ./\n",
    "cp vision/references/detection/coco_eval.py ./\n",
    "cp vision/references/detection/engine.py ./\n",
    "cp vision/references/detection/coco_utils.py ./\n",
    "cd /notebooks/ml639a/639d/\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "libgl1-mesa-dev is already the newest version (20.0.8-0ubuntu1~18.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.7/site-packages (4.5.4.58)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.21.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "# apt update\n",
    "# DEBIAN_FRONTEND=noninteractive apt-get install -y python3-opencv\n",
    "# #tz prompt. dpkg fix...\n",
    "# don't use gui version. pip install opencv-python\n",
    "# use headless\n",
    "apt-get install -y libgl1-mesa-dev # libgl1-mesa-glx\n",
    "# pip uninstall opencv-python -y\n",
    "pip install opencv-python-headless opencv-python\n",
    "# #pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages (2.0.4)\n",
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (4.5.4.58)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.21.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.7.2)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.18.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.10.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (3.4.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pycocotools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations) (1.22.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from albumentations) (1.6.3)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from albumentations) (5.4.1)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.3 MB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image<0.19,>=0.16.1\n",
      "  Downloading scikit_image-0.18.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (30.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.2 MB 5.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (4.0.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.5.4-py3-none-any.whl (195 kB)\n",
      "\u001b[K     |████████████████████████████████| 195 kB 31.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations) (9.0.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2.6.3)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 33.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image<0.19,>=0.16.1->albumentations) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Installing collected packages: tifffile, PyWavelets, opencv-python-headless, imageio, scikit-image, qudida, albumentations\n",
      "Successfully installed PyWavelets-1.3.0 albumentations-1.2.0 imageio-2.19.3 opencv-python-headless-4.6.0.66 qudida-0.0.4 scikit-image-0.18.3 tifffile-2022.5.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- ---------\n",
      "absl-py                 1.0.0\n",
      "albumentations          1.1.0\n",
      "argcomplete             1.12.3\n",
      "argon2-cffi             21.1.0\n",
      "attrs                   21.2.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.10.0\n",
      "bleach                  4.1.0\n",
      "blis                    0.7.5\n",
      "boto3                   1.20.4\n",
      "botocore                1.23.4\n",
      "bravado                 11.0.3\n",
      "bravado-core            5.17.0\n",
      "brotlipy                0.7.0\n",
      "cachetools              4.2.4\n",
      "captum                  0.4.1\n",
      "catalogue               2.0.6\n",
      "catalyst                21.10\n",
      "certifi                 2021.10.8\n",
      "cffi                    1.14.6\n",
      "chardet                 4.0.0\n",
      "click                   8.0.3\n",
      "conda                   4.10.3\n",
      "conda-build             3.21.5\n",
      "conda-package-handling  1.7.3\n",
      "configparser            5.1.0\n",
      "cryptography            3.4.8\n",
      "cycler                  0.11.0\n",
      "cymem                   2.0.6\n",
      "debugpy                 1.5.1\n",
      "decorator               5.1.0\n",
      "defusedxml              0.7.1\n",
      "dnspython               2.1.0\n",
      "docker-pycreds          0.4.0\n",
      "entrypoints             0.3\n",
      "fastai                  2.5.4\n",
      "fastcore                1.3.28\n",
      "fastdownload            0.0.5\n",
      "fastprogress            1.0.0\n",
      "fastrelease             0.1.12\n",
      "filelock                3.0.12\n",
      "future                  0.18.2\n",
      "ghapi                   0.1.19\n",
      "gitdb                   4.0.9\n",
      "GitPython               3.1.24\n",
      "glob2                   0.7\n",
      "google-auth             2.3.3\n",
      "google-auth-oauthlib    0.4.6\n",
      "graphviz                0.18\n",
      "grpcio                  1.41.1\n",
      "hydra-slayer            0.3.0\n",
      "idna                    2.10\n",
      "imageio                 2.10.3\n",
      "importlib-metadata      4.8.2\n",
      "ipykernel               6.5.0\n",
      "ipython                 7.27.0\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              7.6.5\n",
      "jedi                    0.18.0\n",
      "Jinja2                  2.11.3\n",
      "jmespath                0.10.0\n",
      "joblib                  1.1.0\n",
      "jsonpointer             2.2\n",
      "jsonref                 0.2\n",
      "jsonschema              3.2.0\n",
      "jupyter                 1.0.0\n",
      "jupyter-client          6.1.12\n",
      "jupyter-console         6.4.0\n",
      "jupyter-core            4.9.1\n",
      "jupyterlab-widgets      1.0.2\n",
      "kiwisolver              1.3.2\n",
      "kornia                  0.6.1\n",
      "langcodes               3.3.0\n",
      "libarchive-c            2.9\n",
      "Markdown                3.3.4\n",
      "MarkupSafe              2.0.1\n",
      "matplotlib              3.4.3\n",
      "matplotlib-inline       0.1.2\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.3.1\n",
      "mkl-random              1.2.2\n",
      "mkl-service             2.4.0\n",
      "monotonic               1.6\n",
      "msgpack                 1.0.2\n",
      "murmurhash              1.0.6\n",
      "nbconvert               5.6.1\n",
      "nbdev                   1.1.23\n",
      "nbformat                5.1.3\n",
      "neptune-client          0.13.1\n",
      "networkx                2.6.3\n",
      "notebook                6.4.5\n",
      "numpy                   1.21.2\n",
      "oauthlib                3.1.1\n",
      "olefile                 0.46\n",
      "opencv-python           4.5.4.58\n",
      "opencv-python-headless  4.5.4.58\n",
      "packaging               21.2\n",
      "pandas                  1.3.4\n",
      "pandocfilters           1.5.0\n",
      "parso                   0.8.2\n",
      "pathtools               0.1.2\n",
      "pathy                   0.6.1\n",
      "pexpect                 4.8.0\n",
      "pickleshare             0.7.5\n",
      "Pillow                  8.4.0\n",
      "pip                     21.0.1\n",
      "pkginfo                 1.7.1\n",
      "preshed                 3.0.6\n",
      "prometheus-client       0.12.0\n",
      "promise                 2.3\n",
      "prompt-toolkit          3.0.20\n",
      "protobuf                3.19.1\n",
      "psutil                  5.8.0\n",
      "ptyprocess              0.7.0\n",
      "pyarrow                 6.0.0\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycocotools             2.0.4\n",
      "pycosat                 0.6.3\n",
      "pycparser               2.20\n",
      "pydantic                1.8.2\n",
      "pydicom                 2.2.2\n",
      "Pygments                2.10.0\n",
      "PyJWT                   2.3.0\n",
      "pyOpenSSL               20.0.1\n",
      "pyparsing               2.4.7\n",
      "pyrsistent              0.18.0\n",
      "PySocks                 1.7.1\n",
      "python-dateutil         2.8.2\n",
      "python-etcd             0.4.5\n",
      "pytz                    2021.3\n",
      "PyWavelets              1.2.0\n",
      "PyYAML                  5.4.1\n",
      "pyzmq                   22.3.0\n",
      "qtconsole               5.2.0\n",
      "QtPy                    1.11.2\n",
      "qudida                  0.0.4\n",
      "requests                2.25.1\n",
      "requests-oauthlib       1.3.0\n",
      "rfc3987                 1.3.8\n",
      "rsa                     4.7.2\n",
      "ruamel-yaml-conda       0.15.100\n",
      "s3transfer              0.5.0\n",
      "scikit-image            0.18.3\n",
      "scikit-learn            1.0.1\n",
      "scipy                   1.7.2\n",
      "Send2Trash              1.8.0\n",
      "sentencepiece           0.1.86\n",
      "sentry-sdk              1.4.3\n",
      "setuptools              58.0.4\n",
      "shortuuid               1.0.8\n",
      "simplejson              3.17.5\n",
      "six                     1.16.0\n",
      "smart-open              5.2.1\n",
      "smmap                   5.0.0\n",
      "soupsieve               2.2.1\n",
      "spacy                   3.2.0\n",
      "spacy-legacy            3.0.8\n",
      "spacy-loggers           1.0.1\n",
      "srsly                   2.4.2\n",
      "strict-rfc3339          0.7\n",
      "subprocess32            3.5.4\n",
      "swagger-spec-validator  2.7.4\n",
      "tensorboard             2.7.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.0\n",
      "tensorboardX            2.2\n",
      "termcolor               1.1.0\n",
      "terminado               0.12.1\n",
      "testpath                0.5.0\n",
      "thinc                   8.0.13\n",
      "threadpoolctl           3.0.0\n",
      "tifffile                2021.11.2\n",
      "torch                   1.10.0\n",
      "torchelastic            0.2.0\n",
      "torchtext               0.11.0\n",
      "torchvision             0.11.0\n",
      "tornado                 6.1\n",
      "tqdm                    4.61.2\n",
      "traitlets               5.1.0\n",
      "typer                   0.4.0\n",
      "typing-extensions       3.10.0.2\n",
      "urllib3                 1.26.6\n",
      "wandb                   0.12.6\n",
      "wasabi                  0.8.2\n",
      "wcwidth                 0.2.5\n",
      "webcolors               1.11.1\n",
      "webencodings            0.5.1\n",
      "websocket-client        1.2.1\n",
      "Werkzeug                2.0.2\n",
      "wheel                   0.36.2\n",
      "widgetsnbextension      3.5.2\n",
      "yaspin                  2.1.0\n",
      "zipp                    3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                        main  \n",
      "_openmp_mutex             4.5                       1_gnu  \n",
      "absl-py                   1.0.0                    pypi_0    pypi\n",
      "albumentations            1.1.0                    pypi_0    pypi\n",
      "argcomplete               1.12.3                   pypi_0    pypi\n",
      "argon2-cffi               21.1.0                   pypi_0    pypi\n",
      "attrs                     21.2.0                   pypi_0    pypi\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "beautifulsoup4            4.10.0             pyh06a4308_0  \n",
      "blas                      1.0                         mkl  \n",
      "bleach                    4.1.0                    pypi_0    pypi\n",
      "blis                      0.7.5                    pypi_0    pypi\n",
      "boto3                     1.20.4                   pypi_0    pypi\n",
      "botocore                  1.23.4                   pypi_0    pypi\n",
      "bravado                   11.0.3                   pypi_0    pypi\n",
      "bravado-core              5.17.0                   pypi_0    pypi\n",
      "brotlipy                  0.7.0           py37h27cfd23_1003  \n",
      "bzip2                     1.0.8                h7b6447c_0  \n",
      "ca-certificates           2021.9.30            h06a4308_1  \n",
      "cachetools                4.2.4                    pypi_0    pypi\n",
      "captum                    0.4.1                    pypi_0    pypi\n",
      "catalogue                 2.0.6                    pypi_0    pypi\n",
      "catalyst                  21.10                    pypi_0    pypi\n",
      "certifi                   2021.10.8        py37h06a4308_0  \n",
      "cffi                      1.14.6           py37h400218f_0  \n",
      "chardet                   4.0.0           py37h06a4308_1003  \n",
      "click                     8.0.3                    pypi_0    pypi\n",
      "conda                     4.10.3           py37h06a4308_0  \n",
      "conda-build               3.21.5           py37h06a4308_0  \n",
      "conda-package-handling    1.7.3            py37h27cfd23_1  \n",
      "configparser              5.1.0                    pypi_0    pypi\n",
      "cryptography              3.4.8            py37hd23ed53_0  \n",
      "cudatoolkit               11.3.1               ha36c431_9    nvidia\n",
      "cycler                    0.11.0                   pypi_0    pypi\n",
      "cymem                     2.0.6                    pypi_0    pypi\n",
      "debugpy                   1.5.1                    pypi_0    pypi\n",
      "decorator                 5.1.0              pyhd3eb1b0_0  \n",
      "defusedxml                0.7.1                    pypi_0    pypi\n",
      "dnspython                 2.1.0                    pypi_0    pypi\n",
      "docker-pycreds            0.4.0                    pypi_0    pypi\n",
      "entrypoints               0.3                      pypi_0    pypi\n",
      "fastai                    2.5.4                    pypi_0    pypi\n",
      "fastcore                  1.3.28                   pypi_0    pypi\n",
      "fastdownload              0.0.5                    pypi_0    pypi\n",
      "fastprogress              1.0.0                    pypi_0    pypi\n",
      "fastrelease               0.1.12                   pypi_0    pypi\n",
      "ffmpeg                    4.3                  hf484d3e_0    pytorch\n",
      "filelock                  3.0.12             pyhd3eb1b0_1  \n",
      "freetype                  2.10.4               h5ab3b9f_0  \n",
      "future                    0.18.2                   pypi_0    pypi\n",
      "ghapi                     0.1.19                   pypi_0    pypi\n",
      "giflib                    5.2.1                h7b6447c_0  \n",
      "gitdb                     4.0.9                    pypi_0    pypi\n",
      "gitpython                 3.1.24                   pypi_0    pypi\n",
      "glob2                     0.7                pyhd3eb1b0_0  \n",
      "gmp                       6.2.1                h2531618_2  \n",
      "gnutls                    3.6.15               he1e5248_0  \n",
      "google-auth               2.3.3                    pypi_0    pypi\n",
      "google-auth-oauthlib      0.4.6                    pypi_0    pypi\n",
      "grpcio                    1.41.1                   pypi_0    pypi\n",
      "hydra-slayer              0.3.0                    pypi_0    pypi\n",
      "icu                       58.2                 he6710b0_3  \n",
      "idna                      2.10               pyhd3eb1b0_0  \n",
      "imageio                   2.10.3                   pypi_0    pypi\n",
      "importlib-metadata        4.8.2                    pypi_0    pypi\n",
      "intel-openmp              2021.3.0          h06a4308_3350  \n",
      "ipykernel                 6.5.0                    pypi_0    pypi\n",
      "ipython                   7.27.0           py37hb070fc8_0  \n",
      "ipython-genutils          0.2.0                    pypi_0    pypi\n",
      "ipywidgets                7.6.5                    pypi_0    pypi\n",
      "jedi                      0.18.0           py37h06a4308_1  \n",
      "jinja2                    2.11.3             pyhd3eb1b0_0  \n",
      "jmespath                  0.10.0                   pypi_0    pypi\n",
      "joblib                    1.1.0                    pypi_0    pypi\n",
      "jpeg                      9d                   h7f8727e_0  \n",
      "jsonpointer               2.2                      pypi_0    pypi\n",
      "jsonref                   0.2                      pypi_0    pypi\n",
      "jsonschema                3.2.0                    pypi_0    pypi\n",
      "jupyter                   1.0.0                    pypi_0    pypi\n",
      "jupyter-client            6.1.12                   pypi_0    pypi\n",
      "jupyter-console           6.4.0                    pypi_0    pypi\n",
      "jupyter-core              4.9.1                    pypi_0    pypi\n",
      "jupyterlab-widgets        1.0.2                    pypi_0    pypi\n",
      "kiwisolver                1.3.2                    pypi_0    pypi\n",
      "kornia                    0.6.1                    pypi_0    pypi\n",
      "lame                      3.100                h7b6447c_0  \n",
      "langcodes                 3.3.0                    pypi_0    pypi\n",
      "lcms2                     2.12                 h3be6417_0  \n",
      "ld_impl_linux-64          2.35.1               h7274673_9  \n",
      "libarchive                3.4.2                h62408e4_0  \n",
      "libffi                    3.3                  he6710b0_2  \n",
      "libgcc-ng                 9.3.0               h5101ec6_17  \n",
      "libgomp                   9.3.0               h5101ec6_17  \n",
      "libiconv                  1.15                 h63c8f33_5  \n",
      "libidn2                   2.3.2                h7f8727e_0  \n",
      "liblief                   0.10.1               he6710b0_0  \n",
      "libpng                    1.6.37               hbc83047_0  \n",
      "libstdcxx-ng              9.3.0               hd4cf53a_17  \n",
      "libtasn1                  4.16.0               h27cfd23_0  \n",
      "libtiff                   4.2.0                h85742a9_0  \n",
      "libunistring              0.9.10               h27cfd23_0  \n",
      "libuv                     1.40.0               h7b6447c_0  \n",
      "libwebp                   1.2.0                h89dd481_0  \n",
      "libwebp-base              1.2.0                h27cfd23_0  \n",
      "libxml2                   2.9.12               h03d6c58_0  \n",
      "lz4-c                     1.9.3                h295c915_1  \n",
      "markdown                  3.3.4                    pypi_0    pypi\n",
      "markupsafe                2.0.1            py37h27cfd23_0  \n",
      "matplotlib                3.4.3                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.2              pyhd3eb1b0_2  \n",
      "mistune                   0.8.4                    pypi_0    pypi\n",
      "mkl                       2021.3.0           h06a4308_520  \n",
      "mkl-service               2.4.0            py37h7f8727e_0  \n",
      "mkl_fft                   1.3.1            py37hd3c417c_0  \n",
      "mkl_random                1.2.2            py37h51133e4_0  \n",
      "monotonic                 1.6                      pypi_0    pypi\n",
      "msgpack                   1.0.2                    pypi_0    pypi\n",
      "murmurhash                1.0.6                    pypi_0    pypi\n",
      "nbconvert                 5.6.1                    pypi_0    pypi\n",
      "nbdev                     1.1.23                   pypi_0    pypi\n",
      "nbformat                  5.1.3                    pypi_0    pypi\n",
      "ncurses                   6.2                  he6710b0_1  \n",
      "neptune-client            0.13.1                   pypi_0    pypi\n",
      "nettle                    3.7.3                hbbd107a_1  \n",
      "networkx                  2.6.3                    pypi_0    pypi\n",
      "notebook                  6.4.5                    pypi_0    pypi\n",
      "numpy                     1.21.2           py37h20f2e39_0  \n",
      "numpy-base                1.21.2           py37h79a1101_0  \n",
      "oauthlib                  3.1.1                    pypi_0    pypi\n",
      "olefile                   0.46                     py37_0  \n",
      "opencv-python             4.5.4.58                 pypi_0    pypi\n",
      "opencv-python-headless    4.5.4.58                 pypi_0    pypi\n",
      "openh264                  2.1.0                hd408876_0  \n",
      "openssl                   1.1.1l               h7f8727e_0  \n",
      "packaging                 21.2                     pypi_0    pypi\n",
      "pandas                    1.3.4                    pypi_0    pypi\n",
      "pandocfilters             1.5.0                    pypi_0    pypi\n",
      "parso                     0.8.2              pyhd3eb1b0_0  \n",
      "patchelf                  0.13                 h295c915_0  \n",
      "pathtools                 0.1.2                    pypi_0    pypi\n",
      "pathy                     0.6.1                    pypi_0    pypi\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3  \n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    8.4.0            py37h5aabda8_0  \n",
      "pip                       21.0.1           py37h06a4308_0  \n",
      "pkginfo                   1.7.1            py37h06a4308_0  \n",
      "preshed                   3.0.6                    pypi_0    pypi\n",
      "prometheus-client         0.12.0                   pypi_0    pypi\n",
      "promise                   2.3                      pypi_0    pypi\n",
      "prompt-toolkit            3.0.20             pyhd3eb1b0_0  \n",
      "protobuf                  3.19.1                   pypi_0    pypi\n",
      "psutil                    5.8.0            py37h27cfd23_1  \n",
      "ptyprocess                0.7.0              pyhd3eb1b0_2  \n",
      "py-lief                   0.10.1           py37h403a769_0  \n",
      "pyarrow                   6.0.0                    pypi_0    pypi\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\n",
      "pycocotools               2.0.4                    pypi_0    pypi\n",
      "pycosat                   0.6.3            py37h27cfd23_0  \n",
      "pycparser                 2.20                       py_2  \n",
      "pydantic                  1.8.2                    pypi_0    pypi\n",
      "pydicom                   2.2.2                    pypi_0    pypi\n",
      "pygments                  2.10.0             pyhd3eb1b0_0  \n",
      "pyjwt                     2.3.0                    pypi_0    pypi\n",
      "pyopenssl                 20.0.1             pyhd3eb1b0_1  \n",
      "pyparsing                 2.4.7                    pypi_0    pypi\n",
      "pyrsistent                0.18.0                   pypi_0    pypi\n",
      "pysocks                   1.7.1                    py37_1  \n",
      "python                    3.7.11               h12debd9_0  \n",
      "python-dateutil           2.8.2                    pypi_0    pypi\n",
      "python-etcd               0.4.5                    pypi_0    pypi\n",
      "python-graphviz           0.18                     pypi_0    pypi\n",
      "python-libarchive-c       2.9                pyhd3eb1b0_1  \n",
      "pytorch                   1.10.0          py3.7_cuda11.3_cudnn8.2.0_0    pytorch\n",
      "pytorch-mutex             1.0                        cuda    pytorch\n",
      "pytz                      2021.3             pyhd3eb1b0_0  \n",
      "pywavelets                1.2.0                    pypi_0    pypi\n",
      "pyyaml                    5.4.1            py37h27cfd23_1  \n",
      "pyzmq                     22.3.0                   pypi_0    pypi\n",
      "qtconsole                 5.2.0                    pypi_0    pypi\n",
      "qtpy                      1.11.2                   pypi_0    pypi\n",
      "qudida                    0.0.4                    pypi_0    pypi\n",
      "readline                  8.1                  h27cfd23_0  \n",
      "requests                  2.25.1             pyhd3eb1b0_0  \n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\n",
      "rfc3987                   1.3.8                    pypi_0    pypi\n",
      "ripgrep                   12.1.1                        0  \n",
      "rsa                       4.7.2                    pypi_0    pypi\n",
      "ruamel_yaml               0.15.100         py37h27cfd23_0  \n",
      "s3transfer                0.5.0                    pypi_0    pypi\n",
      "scikit-image              0.18.3                   pypi_0    pypi\n",
      "scikit-learn              1.0.1                    pypi_0    pypi\n",
      "scipy                     1.7.2                    pypi_0    pypi\n",
      "send2trash                1.8.0                    pypi_0    pypi\n",
      "sentencepiece             0.1.86                   pypi_0    pypi\n",
      "sentry-sdk                1.4.3                    pypi_0    pypi\n",
      "setuptools                58.0.4           py37h06a4308_0  \n",
      "shortuuid                 1.0.8                    pypi_0    pypi\n",
      "simplejson                3.17.5                   pypi_0    pypi\n",
      "six                       1.16.0             pyhd3eb1b0_0  \n",
      "smart-open                5.2.1                    pypi_0    pypi\n",
      "smmap                     5.0.0                    pypi_0    pypi\n",
      "soupsieve                 2.2.1              pyhd3eb1b0_0  \n",
      "spacy                     3.2.0                    pypi_0    pypi\n",
      "spacy-legacy              3.0.8                    pypi_0    pypi\n",
      "spacy-loggers             1.0.1                    pypi_0    pypi\n",
      "sqlite                    3.36.0               hc218d9a_0  \n",
      "srsly                     2.4.2                    pypi_0    pypi\n",
      "strict-rfc3339            0.7                      pypi_0    pypi\n",
      "subprocess32              3.5.4                    pypi_0    pypi\n",
      "swagger-spec-validator    2.7.4                    pypi_0    pypi\n",
      "tensorboard               2.7.0                    pypi_0    pypi\n",
      "tensorboard-data-server   0.6.1                    pypi_0    pypi\n",
      "tensorboard-plugin-wit    1.8.0                    pypi_0    pypi\n",
      "tensorboardx              2.2                      pypi_0    pypi\n",
      "termcolor                 1.1.0                    pypi_0    pypi\n",
      "terminado                 0.12.1                   pypi_0    pypi\n",
      "testpath                  0.5.0                    pypi_0    pypi\n",
      "thinc                     8.0.13                   pypi_0    pypi\n",
      "threadpoolctl             3.0.0                    pypi_0    pypi\n",
      "tifffile                  2021.11.2                pypi_0    pypi\n",
      "tk                        8.6.10               hbc83047_0  \n",
      "torchelastic              0.2.0                    pypi_0    pypi\n",
      "torchtext                 0.11.0                     py37    pytorch\n",
      "torchvision               0.11.0               py37_cu113    pytorch\n",
      "tornado                   6.1                      pypi_0    pypi\n",
      "tqdm                      4.61.2             pyhd3eb1b0_1  \n",
      "traitlets                 5.1.0              pyhd3eb1b0_0  \n",
      "typer                     0.4.0                    pypi_0    pypi\n",
      "typing_extensions         3.10.0.2           pyh06a4308_0  \n",
      "tzdata                    2021a                h52ac0ba_0  \n",
      "urllib3                   1.26.6             pyhd3eb1b0_1  \n",
      "wandb                     0.12.6                   pypi_0    pypi\n",
      "wasabi                    0.8.2                    pypi_0    pypi\n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
      "webcolors                 1.11.1                   pypi_0    pypi\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "websocket-client          1.2.1                    pypi_0    pypi\n",
      "werkzeug                  2.0.2                    pypi_0    pypi\n",
      "wheel                     0.36.2             pyhd3eb1b0_0  \n",
      "widgetsnbextension        3.5.2                    pypi_0    pypi\n",
      "xz                        5.2.5                h7b6447c_0  \n",
      "yaml                      0.2.5                h7b6447c_0  \n",
      "yaspin                    2.1.0                    pypi_0    pypi\n",
      "zipp                      3.6.0                    pypi_0    pypi\n",
      "zlib                      1.2.11               h7b6447c_3  \n",
      "zstd                      1.4.9                haebb681_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /opt/conda\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python and ML Libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We will be reading images using OpenCV\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# xml library for parsing xml files\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as torchtrans  \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# these are the helper libraries imported.\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "# for image augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/ml639a/639d\n"
     ]
    }
   ],
   "source": [
    "# Settings:\n",
    "\n",
    "!pwd\n",
    "\n",
    "files_dir = '../ir4/trainval/'\n",
    "test_dir  = '../ir4/test/'\n",
    "\n",
    "# files_dir = '../../imgdata/inrm5/trainval/'\n",
    "# test_dir  = '../../imgdata/inrm5/test/'\n",
    "\n",
    "\n",
    "setwidth = 260\n",
    "\n",
    "#setheight = 7990  gives assertionerror. 7500 works.\n",
    "setheight = 7500\n",
    "\n",
    "img_file_suffix = 'edit this below in the code'\n",
    "\n",
    "setclasses = \"  ****   edit below   **** self.classes = [_, 'Chip', 'Crack']  ****  \"  \n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "test_split = 0.5\n",
    "\n",
    "num_epochs = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect one image.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7990, 260, 3)\n",
      "PNG\n",
      "../ir4/trainval/inner_rim_210805T103940.png\n"
     ]
    }
   ],
   "source": [
    "imgs = [image for image in sorted(os.listdir(files_dir))\n",
    "                    if image[-4:]=='.png']\n",
    "\n",
    "img_name = imgs[1]\n",
    "image_path = os.path.join(files_dir, img_name)\n",
    "\n",
    "# reading the images and converting them to correct size and color    \n",
    "import cv2\n",
    "img = cv2.imread(image_path)\n",
    "imgp = Image.open(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "#img_res = cv2.resize(img_rgb, (width, height), cv2.INTER_AREA)\n",
    "# diving by 255\n",
    "# img_res /= 255.0\n",
    "\n",
    "print( img.shape)\n",
    "print( imgp.format)\n",
    "print( image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build the images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining the files directory and testing directory\n",
    "# files_dir = '../cast04c/train'\n",
    "# test_dir = '../cast04c/test'\n",
    "# files_dir = '../imgdata/sg/s1out/train/'\n",
    "# test_dir = '../imgdata/sg/s1out/test/'\n",
    "\n",
    "\n",
    "class AaImagesDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, files_dir, width, height, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.files_dir = files_dir\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # sorting the images for consistency\n",
    "        # To get images, the extension of the filename is checked to be jpg\n",
    "        self.imgs = [image for image in sorted(os.listdir(files_dir))\n",
    "                        if image[-4:]=='.png']\n",
    "        \n",
    "        # classes: 0 index is reserved for background\n",
    "        self.classes = [_, 'Chip']\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_name = self.imgs[idx]\n",
    "        image_path = os.path.join(self.files_dir, img_name)\n",
    "\n",
    "        # reading the images and converting them to correct size and color    \n",
    "        img = cv2.imread(image_path)\n",
    "        imgp = Image.open(image_path)\n",
    "        #print(idx, imgp.format)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img_res = cv2.resize(img_rgb, (self.width, self.height), cv2.INTER_AREA)\n",
    "        # diving by 255\n",
    "        img_res /= 255.0\n",
    "        \n",
    "        # annotation file\n",
    "        annot_filename = img_name[:-4] + '.xml'\n",
    "        annot_file_path = os.path.join(self.files_dir, annot_filename)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        tree = et.parse(annot_file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # cv2 image gives size as height x width\n",
    "        wt = img.shape[1]\n",
    "        ht = img.shape[0]\n",
    "        \n",
    "        # box coordinates for xml files are extracted and corrected for image size given\n",
    "        for member in root.findall('object'):\n",
    "            labels.append(self.classes.index(member.find('name').text))\n",
    "            \n",
    "            # bounding box\n",
    "            xmin = int(member.find('bndbox').find('xmin').text)\n",
    "            xmax = int(member.find('bndbox').find('xmax').text)\n",
    "            \n",
    "            ymin = int(member.find('bndbox').find('ymin').text)\n",
    "            ymax = int(member.find('bndbox').find('ymax').text)\n",
    "            \n",
    "            xmin_corr = (xmin/wt)*self.width\n",
    "            xmax_corr = (xmax/wt)*self.width\n",
    "            ymin_corr = (ymin/ht)*self.height\n",
    "            ymax_corr = (ymax/ht)*self.height\n",
    "            \n",
    "            boxes.append([xmin_corr, ymin_corr, xmax_corr, ymax_corr])\n",
    "        \n",
    "        # convert boxes into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        # getting the areas of the boxes\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        # image_id\n",
    "        image_id = torch.tensor([idx])\n",
    "        target[\"image_id\"] = image_id\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image = img_res,\n",
    "                                     bboxes = target['boxes'],\n",
    "                                     labels = labels)\n",
    "            img_res = sample['image']\n",
    "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
    "                       \n",
    "        return img_res, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset =  5 \n",
      "\n",
      "(7500, 260, 3) \n",
      " {'boxes': tensor([[1.0000e+00, 6.3492e+03, 1.7300e+02, 6.5379e+03]]), 'labels': tensor([1]), 'area': tensor([32451.8145]), 'iscrowd': tensor([0]), 'image_id': tensor([0])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check dataset\n",
    "dataset = AaImagesDataset(files_dir, setwidth, setheight)\n",
    "print('length of dataset = ', len(dataset), '\\n')\n",
    "\n",
    "# getting the image and target for a test index.  Feel free to change the index.\n",
    "img, target = dataset[0]\n",
    "print(img.shape, '\\n',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points to be noted -\n",
    "1. The dataset returns a tuple. The first element is the image shape and the second element is a dictionary.\n",
    "2. The image is of the size, we provided while defining the dataset and the color mode is RGB.\n",
    "3. There are four bounding boxes in the image which is evident from four lists in boxes and length of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And its done! \n",
    "\n",
    "Dataset building is one of the hardest things in the notebook. If you got till here while understand all of the above, you are doing pretty good!\n",
    "\n",
    "Let's now see, what our data looks like. The function is inspired from [here](https://www.kaggle.com/kiwifairy/visualize-x-ray-image-with-bounding-boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 1.2663e+03, 1.9700e+02, 1.6399e+03])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img: [[[0.15345359 0.15345359 0.15345359]\n",
      "  [0.1716523  0.1716523  0.1716523 ]\n",
      "  [0.17139608 0.17139608 0.17139608]\n",
      "  ...\n",
      "  [0.20353724 0.20353724 0.20353724]\n",
      "  [0.20353724 0.20353724 0.20353724]\n",
      "  [0.19228497 0.19228497 0.19228497]]\n",
      "\n",
      " [[0.1670902  0.1670902  0.1670902 ]\n",
      "  [0.14509805 0.14509805 0.14509805]\n",
      "  [0.14109804 0.14109804 0.14109804]\n",
      "  ...\n",
      "  [0.19292548 0.19292548 0.19292548]\n",
      "  [0.19292548 0.19292548 0.19292548]\n",
      "  [0.19569412 0.19569412 0.19569412]]\n",
      "\n",
      " [[0.15037909 0.15037909 0.15037909]\n",
      "  [0.14766012 0.14766012 0.14766012]\n",
      "  [0.17903268 0.17903268 0.17903268]\n",
      "  ...\n",
      "  [0.19935948 0.19935948 0.19935948]\n",
      "  [0.20064051 0.20064051 0.20064051]\n",
      "  [0.19215687 0.19215687 0.19215687]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.16199449 0.16199449 0.16199449]\n",
      "  [0.16862746 0.16862746 0.16862746]\n",
      "  [0.18438649 0.18438649 0.18438649]\n",
      "  ...\n",
      "  [0.19935854 0.19935854 0.19935854]\n",
      "  [0.19607843 0.19607843 0.19607843]\n",
      "  [0.19408126 0.19408126 0.19408126]]\n",
      "\n",
      " [[0.1391793  0.1391793  0.1391793 ]\n",
      "  [0.14387064 0.14387064 0.14387064]\n",
      "  [0.17408854 0.17408854 0.17408854]\n",
      "  ...\n",
      "  [0.19292663 0.19292663 0.19292663]\n",
      "  [0.19961512 0.19961512 0.19961512]\n",
      "  [0.19215687 0.19215687 0.19215687]]\n",
      "\n",
      " [[0.12587507 0.12587507 0.12587507]\n",
      "  [0.12979664 0.12979664 0.12979664]\n",
      "  [0.15358265 0.15358265 0.15358265]\n",
      "  ...\n",
      "  [0.19595014 0.19595014 0.19595014]\n",
      "  [0.1848269  0.1848269  0.1848269 ]\n",
      "  [0.19215687 0.19215687 0.19215687]]] targ: {'boxes': tensor([[1.0000e+00, 1.2663e+03, 1.9700e+02, 1.6399e+03]]), 'labels': tensor([1]), 'area': tensor([73224.0156]), 'iscrowd': tensor([0]), 'image_id': tensor([1])}\n"
     ]
    }
   ],
   "source": [
    "# Function to visualize bounding boxes in the image\n",
    "\n",
    "def plot_img_bbox(img, target):\n",
    "    # plot the image and bboxes\n",
    "    # Bounding boxes are defined as follows: x-min y-min width height\n",
    "    fig, a = plt.subplots(1,1)\n",
    "    fig.set_size_inches(5,5)\n",
    "    a.imshow(img)\n",
    "    for box in ((target['boxes']).cpu()):\n",
    "        print(box)\n",
    "        x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "        rect = patches.Rectangle((x, y),\n",
    "                                 width, height,\n",
    "                                 linewidth = 2,\n",
    "                                 edgecolor = 'r',\n",
    "                                 facecolor = 'none')\n",
    "\n",
    "        # Draw the bounding box on top of the image\n",
    "        a.add_patch(rect)\n",
    "    plt.show()\n",
    "    \n",
    "# plotting the image with bboxes. Feel free to change the index\n",
    "img, target = dataset[1]\n",
    "plot_img_bbox(img, target)\n",
    "print(\"img:\",img,\"targ:\",target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we are doing great till now, as the bbox is correctly placed. \n",
    "\n",
    "Lets build the model then!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a function for loading the model. We will call it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_object_detection_model(num_classes):\n",
    "\n",
    "    # load a model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see, how easy it is to load and prepare the model using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we can apply augmentations to the image. \n",
    "\n",
    "The augmentations to object detection vary from normal augmentations becuase here we need to ensure that, bbox still aligns with the object correctly after transforming.\n",
    "\n",
    "Here I have added random flip transform, feel free to customize it as you feel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send train=True fro training transforms and False for val/test transforms\n",
    "def get_transform(train):\n",
    "    \n",
    "    if train:\n",
    "        return A.Compose([\n",
    "                            A.HorizontalFlip(0.5),\n",
    "                     # ToTensorV2 converts image to pytorch tensor without div by 255\n",
    "                            ToTensorV2(p=1.0) \n",
    "                        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    else:\n",
    "        return A.Compose([\n",
    "                            ToTensorV2(p=1.0)\n",
    "                        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets prepare datasets and dataloaders for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = AaImagesDataset(files_dir,  setwidth, setheight, transforms= get_transform(train=True))\n",
    "dataset_test = AaImagesDataset(files_dir, setwidth, setheight, transforms= get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "# train test split\n",
    "# test_split = 0.5\n",
    "tsize = int(len(dataset)*test_split)\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-tsize])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-tsize:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=10, shuffle=True, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=10, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train on gpu if selected.\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_object_detection_model(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the training begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [0/1]  eta: 0:00:06  lr: 0.000005  loss: 1.1654 (1.1654)  loss_classifier: 0.9753 (0.9753)  loss_box_reg: 0.0757 (0.0757)  loss_objectness: 0.1064 (0.1064)  loss_rpn_box_reg: 0.0080 (0.0080)  time: 6.6387  data: 1.0879  max mem: 793\n",
      "Epoch: [0] Total time: 0:00:06 (6.6879 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/1]  eta: 0:00:01  model_time: 0.0695 (0.0695)  evaluator_time: 0.0147 (0.0147)  time: 1.5795  data: 1.4827  max mem: 885\n",
      "Test: Total time: 0:00:01 (1.6458 s / it)\n",
      "Averaged stats: model_time: 0.0695 (0.0695)  evaluator_time: 0.0147 (0.0147)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.00301\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.00902\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.20000\n",
      "Epoch: [1]  [0/1]  eta: 0:00:00  lr: 0.000005  loss: 1.1561 (1.1561)  loss_classifier: 0.9726 (0.9726)  loss_box_reg: 0.0757 (0.0757)  loss_objectness: 0.0998 (0.0998)  loss_rpn_box_reg: 0.0080 (0.0080)  time: 0.8569  data: 0.6651  max mem: 1105\n",
      "Epoch: [1] Total time: 0:00:00 (0.9234 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/1]  eta: 0:00:00  model_time: 0.0555 (0.0555)  evaluator_time: 0.0134 (0.0134)  time: 0.5342  data: 0.4541  max mem: 1105\n",
      "Test: Total time: 0:00:00 (0.6171 s / it)\n",
      "Averaged stats: model_time: 0.0555 (0.0555)  evaluator_time: 0.0134 (0.0134)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.00317\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.00953\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.20000\n",
      "Epoch: [2]  [0/1]  eta: 0:00:01  lr: 0.000005  loss: 1.1540 (1.1540)  loss_classifier: 0.9680 (0.9680)  loss_box_reg: 0.0788 (0.0788)  loss_objectness: 0.0992 (0.0992)  loss_rpn_box_reg: 0.0080 (0.0080)  time: 1.4677  data: 1.2800  max mem: 1106\n",
      "Epoch: [2] Total time: 0:00:01 (1.5400 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/1]  eta: 0:00:00  model_time: 0.0614 (0.0614)  evaluator_time: 0.0144 (0.0144)  time: 0.6038  data: 0.5166  max mem: 1106\n",
      "Test: Total time: 0:00:00 (0.6759 s / it)\n",
      "Averaged stats: model_time: 0.0614 (0.0614)  evaluator_time: 0.0144 (0.0144)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.00328\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.00990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.20000\n",
      "Epoch: [3]  [0/1]  eta: 0:00:01  lr: 0.000001  loss: 1.1479 (1.1479)  loss_classifier: 0.9578 (0.9578)  loss_box_reg: 0.0787 (0.0787)  loss_objectness: 0.1034 (0.1034)  loss_rpn_box_reg: 0.0080 (0.0080)  time: 1.0391  data: 0.8563  max mem: 1106\n",
      "Epoch: [3] Total time: 0:00:01 (1.1016 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/1]  eta: 0:00:00  model_time: 0.0563 (0.0563)  evaluator_time: 0.0140 (0.0140)  time: 0.5653  data: 0.4837  max mem: 1106\n",
      "Test: Total time: 0:00:00 (0.6300 s / it)\n",
      "Averaged stats: model_time: 0.0563 (0.0563)  evaluator_time: 0.0140 (0.0140)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.00328\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.00990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.20000\n",
      "reached.end.\n"
     ]
    }
   ],
   "source": [
    "# training for 10 epochs\n",
    "\n",
    "# edit me..\n",
    "#num_epochs = 3\n",
    "\n",
    "# !export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    # training for one epoch\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "    \n",
    "print('reached.end.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comments\n",
    "\n",
    "An AP of 0.78-0.80 is not bad but perhaps we can make it even better with more augmentations, I will leave that to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicts a lot of bounding boxes per image, to take out the overlapping ones, We will use **Non Max Suppression** if you want to brush up on that, check [this](https://towardsdatascience.com/non-maximum-suppression-nms-93ce178e177c) out.\n",
    "\n",
    "Torchvision provides us a utility to apply nms to our predictions, lets build a function `apply_nms` using that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function takes the original prediction and the iou threshold.\n",
    "\n",
    "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
    "    \n",
    "    # torchvision returns the indices of the bboxes to keep\n",
    "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
    "    \n",
    "    final_prediction = orig_prediction\n",
    "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
    "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
    "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "# function to convert a torchtensor back to PIL image\n",
    "def torch_to_pil(img):\n",
    "    return torchtrans.ToPILImage()(img).convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Generated/trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take an image from our test dataset and see, how our model does.\n",
    "\n",
    "We will first see, how many bounding boxes does our model predict compared to actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted #boxes:  100\n",
      "real #boxes:  1\n"
     ]
    }
   ],
   "source": [
    "# pick one image from the test set\n",
    "img, target = dataset_test[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])[0]\n",
    "    \n",
    "print('predicted #boxes: ', len(prediction['labels']))\n",
    "print('real #boxes: ', len(target['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! Thats a lot of bboxes. Lets plot them and check what did it predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED OUTPUT\n",
      "tensor([1.0000e+00, 4.6033e+03, 1.9200e+02, 4.9684e+03])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAAEzCAYAAABuam47AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAX60lEQVR4nO2da4wkV3XHf6ere7pnZm2v10OwY1itHwS0GGUNZr0oVjBYxgYilg+QmEQJIkjOBxNBHgo2XyAPpJAoIUR5ySEmJiIYxzyCEI+YlyyjgG3ABvxYPGuz9q7tdXZ3dtjZmZ1+nXyoOjWna3tmeqZqau5M718qTXVVT9+6p+4999xz/vdcUVWGHZX1foAQcEYInBECcEYIwBkhAGeEAKyDEETkehHZJyKTInJz2eX3g5RpJ4hIBPwUuBY4CNwPvENVHyntIfqg7JawG5hU1SdUtQncAewt+RlOQ9lCuBB42n0+mFxbV1TX+wGyEJEbgRuT81dt3boVgEqlgqqmR7vdxrryyZMnj6jqC1ZbZtlCOAS82H1+UXIthareCtwKMDo6qtdeey0iwsjICADz8/OoKkeOHKHb7TI3N8d99913IM9Dld0d7gdeIiIXicgIcAPwxeX+SUSoVCp0u9307YtIeuRFqS1BVdsi8h7ga0AE3KaqDy/1P1EU2f+iqqlAiqi8oXSdoKpfBr486PdFBFWl2+2m551Op+deXgRvMZoCtDfvK93tdgspI3ghAHQ6HSqVSnoAPfohLzaEEESETqeDqqYKEmJ9MRTdwWCV7Xa71Gq1jTs6rBZmKNm51w/WPfIgeCHYyFCtxo9qXcF3i7zYEN2h2+32vHHTEUXZCsELod1uA/QoRkO3201thjwIujt0u12efvrpdO7Q7Xbpdru0Wi1OnDhBu91mbm4udzmlOlVWChFRM5uXQqfT+b6qXrHacoJuCUDa/P2IICKpUiziJQYthHq9zp49e4iiiHq9nuqARqPBM888Q7vdZnZ2lsnJyVzlBC0EEWFiYoIoiqjVagC0Wi0ajQazs7OoaupnyIOgRwcRIYqi1DI0Q8lPqIoYJoMWAsRDow2DNmny+qAIizF4IXhHijlW/IgxFBMo6w7eajQDqohWABtACNbnfUuo1+un3c+DoIWQ7fOmKK2LDMXcwVfUhGGtwbDpdYKNBOZctQqPjIwU5mSFDWAsmS7w5nOr1Uq/s+lbAkCz2UwFYa3BfAlFxR+CFoKqUq1W0ym0DZdmJ5gg8iJoIYgIzWYTWHCndbtd2u12qis2fXdQVWq1Wo+ZLCKpt3no4g7+yMYn82JZIYjIbSLyvIj8xF3bJiJ3i8jjyd9zk+siIn+f8JF+JCKvdP/zzuT7j4vIOwd5OF9xGyGsdQA9k6k8GKQl/DtwfebazcA3VPUlwDeSzwBvBF6SHDcC/5xUZhvwQeBKYsrOB01wy8FX0kYCH58sZXRQ1XuAY5nLe4Hbk/Pbgbe665/UGN8FtorIBcB1wN2qekxVp4C7OV2wfeH9B77iIeiEF6rqs8n5c8ALk/PFOEmr4ir5LmAjA/ROpsrqDss9qAKFuaxF5EYReUBEHjDjKOtPOHXqlP9+7jJXK4TDSTMn+ft8cn0xTtKyXCWDqt6qqleo6hXVajXt/0XPHD1WK4QvAqbh3wn8t7v+O8kosQeYTrrN14A3iMi5iUJ8Q3Jt+QfMWIRmRXomW14sO4ESkU8DVwMTInKQWMv/JXCniLwbOAD8evL1LwNvAiaBWeBdyYMfE5E/JyZuAfyZqmaVbV9kJ09AGpy1+3mxrBBU9R2L3Lqmz3cVuGmR37kNuG1FT5egUqn0xBy9khyKCRQs0HUMjUZjuDxL/bxI1Wo1FUARQ2TQTpVut8vhw4cBqNVqqSKcnp5Ow3AnT57MXU7wUWmvBD38c+eNSgfdHaAY7b8cgu4OIyMjXH755URRlAZeW60WExMT7N+/PyVpHDiQi98dthAqlQoXXnghlUqFsbEx2u02zWaT888/n5mZGbrdLjMzM7mFEHx38CxWc6yay20o3GsGbyKrKo1GozD6HmwAIXhOQpbq73kKucoo4DnXDJ6f1I/FOhRUf6ukBWF9PNKTvvMiaCHAghfJWkS32+2JRRRSRiG/soawkFu/vl+ao3W9kfUoGbvVzotA8ELwCztMIENnJ/SLORpdZ71d7qUhOyJUKpU0Oj00QvD9PutcHRqd0O12OXr0KK1WK337dl7UirjghaCqnH322czNzfXQe31oLi+CnkpDrBOMj2CEzqJXwwXfEoy96p2rnU5neFzu0Lvoo1KppPrA+xlyl1HIr6whvKFkk6ixsbGee3kRvBA8RcdaQJFdAQIXgr19mzJb5U+dOtVjPOVF0ELwb9qfj4+PFxqiH4S49WIR+ZaIPCIiD4vIe5PrpZG3bBKVJXGW6VlqA3+kqjuBPcBNIrKTkshb5lqzodK6R1qBMrqDqj6rqj9Izk8AjxLzjUohb5k3ya+cN+vRlGVerMhiFJEdwOXA91gj8pa4PEu1Wq2n8jZXMB5jUXphYCGIyBbgs8D7VPXnmdmdikghg7a6PEuNRkNnZmbS9Y+qSrPZZGpqKp1UzczM5C5zICGISI1YAJ9S1c8llw+LyAWq+uwKyFtXZ65/e6lym80m99xzT09mHYB77723h9CVF4OMDgL8G/Coqv6tu7Xm5C178+12m1arRbvdTuORRSaWGaQl/Arw28CPReTB5NoHKIG8NTIyws6dOxGRlKylqkxMTHDgwAE6nQ6zs7McPHhwwOr2xyDErXuBxTTQmpK3VJVLL72USqVCo9EA4i6yffv2dDHI9PR0biEEbTFak8/6GX0wdtObzX7pj1W82WwyOjqaGk1FpBMJWgjWCuww09mWBBaFoIVglc+OBGY7DMUsMutQgV4d4EP2eRC0o9XmB9C7xuGcc85Jh80g1jusNbIzRjOWhobWa/CZNKrVajCLPkqFTyRhxC0oLiodtE6ABQPJzOZWq8X4+HiPAZUXG6IldLvdNFVxFEXMzMwMVwQqG39U1TTHkjep8yDo7uA9Sn699Pj4eOp83fTdwYfbvA7wLrdN3x0s4OIrrMm6yCImToaghQC92ffg9BytRSBoIWR9BxBXfGxsrO/EarUIWgiwoAPs7ZuXqewI1LrCok9+9dvs7GxPcpm82BBCsKZvb97ysg6FseQ9S76yW7Zs6UkpkhdBCyFL57ckU96CHAp/gk87Zpibm0udrJteJ2StQ0/pLUoAELgQfHfwVH9/bPq10qrK/Px8GnuEmNc4MzPDiRMnmJ+fZ2pqKnc5Qa+VrlQqumXLlp6WYD6F+fl5n4Ys11rp09YcZg+gAdwHPAQ8DPxpcv0iYrLGJPAZYCS5Xk8+Tyb3d7jfuiW5vg+4boCyNYqiZQ/ggeV+a6ljkO4wD7xeVWcSnsK9IvIV4A+Bj6rqHSLyL8C7iflJ7wamVPVSEbkB+AjwGwnP6Qbg5cAvAl8XkV9S1UWng1EUsWPHDiCOUFerVZrNJueeey7PPfccnU6HZrOZphdYLQaJSitgdJBacijweuA3k+u3Ax8iFsLe5BzgLuAfEo7DXuAOVZ0HnhSRSWIC1/8u+nDVKq94xSuIooixsTFU4+3QLrnkEh566CE6nQ5TU1O5hTDQ6CAiUcJNeJ6YcLUfOK6q7eQrnn+UcpOS+9PAeawi4ZQ5WG0ksObrWe5FYCAhqGpHVXcRU2x2Ay8rpPQ+EJdsyiZOfgYJvYz3IrAiO0FVjwPfAl5DTM2z7uSTR6WcpeT+OcBRBkw4pZlkUz4UZ5idne2xG/JiEM7SC0Rka3I+Srzr56PEwnhb8rUsZ8m4TG8DvpnolS8CN4hIXUQuIiZ73jfQQyaWog/R9wvQrhaDjA4XALdLvPVpBbhTVb8kIo8Ad4jIXwA/JCZ3kfz9j0TxHSMeEVDVh0XkTuARYpbsTUuNDAa/JNDsAr8SppQIlKr+iJjAmb3+BLF+yF4/Bbx9kd/6MPDhlTxgFEWnrY00iu8gW6EMgqDnDtCbKsCnMLddPzY9PwF6LVqbTBm7tXRa73rBe5VtuPQJrQspo5BfWUOY38B3C7/yZdP7GD28wVT09gYbQgjZwGxRhC1D0ELwsYZsoMUvFc6LoIVglfaOVptJFhV4gQ0wOsDp2fuLXhsZvBCygRdbMG5dZCjiDtlIk6UYKioYCxtACK1Wq2ei1Ol0ehaAFIHgheD9Bv1SmheBoHWCnyx5ZZhNYZwXwbeETqeTWoimC5rNJrVabXg217a3LiI9i0WLJHMG3R1sBMg6W82XMBTrHWBhFmneJFhQkkPhWerHY/SxiCxvYbUIuiX40Hyr1UqFEkURc3NztFqtzZ/BO4oiPe+884DeHGz1ep3p6Wna7TadTof5+fnNu690t9vl2LGBtoHIhaCFEEUR27Zt66Hp2BKgubm5dFo9PT2dq5yghVCtVtmzZw+VSoXx8fF0XzhbMF6pVDh+/Djf+c538pVT0POuCezNGzfBFGOtVqNarRJFUSHDZNBDJJCG3OD0PWWLmj8EL4RqtdoTgYJ40biPT+bFwEJIiBo/FJEvJZ8vEpHvSZxP6TMiMpJcryefJ5P7O9xv3JJc3yci1y1XphEyvBfJuoN3suTFSlrCe4lD8oaPEHOWLgWmiLlK4DhLwEeT75HhLF0P/FMS6V4UIpIaST4bn80bivIpDErXeRHwZuDjyWch5izdlXwlm2fJ8i/dBVyT5Syp6pPELLbTotqnPWDCSfDeZu94LdPl/nfAnwAm+vMogbMEnGYjWDew0aIIDMJU+TXgeVX9fiElLl9ezwZ5nuVuThQbMYpyqgyaXectIvImYmLn2cDHSDhLydvux1k6uFrOEkmyqdHRUQV63Gs2eyw1Pamq3qKqL1LVHcSK7Zuq+luUyFlKngNY2GHYhsj1dqq8nxI4S7VaLXWoeGZKkXbCioSgqt8mSRVWFmfJ85VslKjX68MVfPGLO3yAtkh+QtATKFhgr8HC3MG8zjAEa6VhYadQWOAkWO7moSFuZXf+sb/egsyL4FtClsxZJE3HsCFagp8vmKXoP+dF8C3B4ElbjUajR2HmxYYQQtazZJyFomyF4IVgs0cvCD86DIUQsjmbLTptbrfFtlddCYJXjJ7gbUOjj0wPTUvw/gQTQJHZejeEEDxVz/sYi6LwBd8dIF7pYu40VU2Hx6JytAYthE6nw+OPP95jIHU6HQ4dOsQzzzxDs9nsSUu4WgQdmhcRHSTMtqk3134V0O50Fj2KmkcELYTlsHXrVs4666zcvxO8EKpR1HNc/drXLtyrVgsxloIXQhbZSg+FsZSFHxKLWvgRvBD8ylj7bBhaxWhbp8LpC0JWiw0lhIsvvpjx8fH0sydw5EHQFiMsNPl6vc6uXbt6ukOj0UhTkeVB8EKAOOHcq1/9amq1Wo9iHBkZSbdDyoPghVCtVtm9ezcTExOn9f+xsTHm5+dzlzEoU+VnIvJjEXlQRB5IrpWyN9yVV15Jo9HomUQZxsbG0t3G82AlWuV1qrrLTVRK2Rtu27Zt1Ov1dPrshSAihQghT3fYy8LmVrcTR6vfj9sbDviuiGyVeLOsq0n2hgMQEdsb7tNLFfL5L3xh0XuNRqMQnTBoS1Dgf0Tk+xLv3QZrtDfcShBFUamO1qtU9ZCI/AJwt4g85m+qFrc3nLgN8qrVKm9/61uBeIRQjfO4n3/++Tz11FOgxeRyHzTZ1KHk7/PA54n79OGkmSOD7w234jxLFob3e0IZu720pJQiMi4iZ9k58Z5uP6GEveGgN5MG9PIYy+QsvRD4fFJYFfhPVf2qiNzPGu8NB/Twmtvtdvq3qFZglVoSCTfpl/tcP8oa7w0HpBX3w6NvBUOxat5vn2qxxyxpIy+CF8JS2XmHxp9gFa1Wq7Tb7Z5F40UpxuCF4IdFiLuH0f+LIm9tCCFkucxFKURD8FNpT+WVZImwz8k4FN5mX1H/9otkqgTdEnxX8KF4U5AWmc6LoIUA9ESdbWvlKIo4fvx4mrI4L4KOSlcqFR0bGwMWCFyewWb2Q9405kG3BFUthH+wHIIWQhRFbN++HYi9SKYfKpUKJ0+eTNOYHzlyJFc5QQuhWq1y2WWXUa1W04UezWaTrVu3cvDgQVSV6enpzS0EGwY9j9kcLMZhLNvbvC7wpG6IRwjvWCli1XzQLcHWQAI9LcG3kKFY/mOVNKPIZpPrtWC8dJgd4PWCX/Xiu0keBC0E6N36zExn6xJDk0TCpwjws8msnyEPgheCVdhMZq8DhmYqnZ0+Z+MPQ+FZMker6QJztvoRIi+CF0I2xuCXBha1YDxoIVjMsV/Fi4xABS0ET9b0C8L8eqihUYw+dYBvAUVl5gxaCNnYY7/+X5oQEsrNXSLymIg8KiKvKYO4ZQkovT3go05lD5EfA76qqi8jjlA/SgnELW8ZZtdG9jOeVotBSBrnAL9KkjNFVZsa7wzmk0plk019UmN8lzgLzwXAdSTELVWdIt5j7vrlyveV9XOI5FlKawkXAf8HfELi3GsfTxgra0Lckj57w/kUQz7yVGZUugq8EvhnVb0cOMlC0wdSYkYh5luWs+T3lfbDZTbPSh4MIoSDwEFV/V7y+S5ioawJccsju0S432SqlO6gqs8BT4vIS5NL1xDnSiqFuAULeRit0tl8S3kxqHvt94FPSZxz8QliMlaFEohbPllEtlsUhYGEoKoPAv3CXGtO3PLDoL11vznWpl8DZU3fO1WzemHTh+aBNAptAVivFJvNJs1mM3cZQQuh3W7z2GOPpXZCpVJhfn6eKIqYmZlJQ/V5EbwQ9u/fv+blBC0EEWF0dDQ999fN2VIEWyVoIYyMjHDVVVel2bq9Y+Xo0aOICKdOneL+++9f/seWQNBCkCSTzsjICI1GI+Uwigj1ej1dFpQXQQ+R0GsgZVsDFBOLDLolePhIVFGJ7A3BtwQfb8gGX4rK4h28EEwp9qP4FxV82RDdIeta9y2giMh08C0Bet981n+w6V3u0JuUMkvqtpEiLzZEdzD4SHSpnqUQkHWpeX/CUIThzECySpt94AMweRG8EEz7W+X9Lh9DswbK9nyx1XDWKoqKOcAGEIJl9Pfbpw5daD5L04Gl7YbVYMMIwb9x3y02fUvwniMThs/NOhR7zftAi40IfrOboWGvmXGU9R/YrmCbfiq9WJ83N1tRCFoIXvP7eYMJoLSE9iLyUomTTNnxcxF5XxmcJTOV/aRJVdOuUVoWPlXdp3GSqV3EuWNniZPLlJJsyhM6swIpCivtDtcA+1X1ACVwlizIYoFZ72hdT7P5BhYyZJWSbMqvfvOzSRs+S7UYE4LGW4D/yt4rkrOUJW75xeLJ/UKT2cPKjKU3Aj9Q1cPJ58MicoGqPrsCztLVmevfzhaiboO8er2uhw8fJoqintmkiDA1NUWn02Fubm4FVVgEWXLUYgdwB/Au9/mvgZuT85uBv0rO3wx8BRBgD3Bfcn0b8CRwbnI8CWxbpkytVqt9jyiK0gN4YNB69C1nQAGME293eI67dh7xqPA48HWrUFL5fwT2Az8GrnD/87vEXKZJL9ClhBBF0ZoLIejUAfV6XS+77DJGR0dTM9mST9le8/Pz80xOTm7e1AGVSoUdO3YQRRH1eh3VeNMbW0CuqszNzTE5OZmvnIKed83gh8eskTRU3mY/nYbeidVQCMHPGbyNYFZkEQhaCJ7h7q9lo1B5EbQQrKl709i2UPXmc14ELQQg3UPaKuu7wFC0BFhQhj5DZ8agyo3ghWApifs5VQoro9BfWwP4CJQkSSMsFaGNEnkRfEvITqEtSe16epZKhyk/byfYdSgmNB98dzBYpYtMS2oIehYpIieAfct8bQIYV9UXrLac0FvCvuWmyCLygKruyFNI8DqhDJwRAuEL4daCvrMkglaMZSH0llAKghWCiFwvIvsk3nlov4g8IiIPi8h7k/sfEpFDLlD8Jve/tyQB4X0ict2yheVxVa/VAUTELvuLge3AT4GdwFnu/EPAH/f5353AQ0CdOO3BfiBaqrxQW8JuYFJVn1DVp4BPAHtV9QRxFo+lYph7gTtUdV5VnySOcexeqrBQhdA3eCsiO4DLAUtj8J6EA3GbC/OvOPAbqhD6oQZ8Fnifqv6cmPdwCbALeBb4m9X+cKhCyAZ1twOvAz6lqp8DUNXDqtpR1S7wryw0+RUnq1h3JbiIYqwS52m4CBgBjhETP/x3LnDnf0CsBwBeTq9ifIJlFGOQEyhVbYvIe4gzbYwTR7F3iciDyVc+ALxDRHYR8yJ+Bvxe8r8Pi8idxNk+2sBNqrpkgOKMxUi4OqFUnBECZ4QAnBECcEYIwBkhAGeEAJwRAgD/D/u31qDpOThaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('EXPECTED OUTPUT')\n",
    "plot_img_bbox(torch_to_pil(img), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('MODEL OUTPUT')\n",
    "plot_img_bbox(torch_to_pil(img), prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our model predicts a lot of bounding boxes for every apple. Lets apply nms to it and see the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMS APPLIED MODEL OUTPUT\n",
      "tensor([   6.2022, 5462.4175,  130.4615, 5688.8037])\n",
      "tensor([   7.2863, 5448.0259,  188.8745, 5608.4341])\n",
      "tensor([   0.0000, 3779.1587,  260.0000, 4176.8164])\n",
      "tensor([   8.7999, 2130.0208,  116.4428, 2360.2910])\n",
      "tensor([   6.6063, 3730.0591,  167.0977, 4281.1021])\n",
      "tensor([   6.7150, 3952.7227,  129.8352, 4174.5508])\n",
      "tensor([  11.5871, 2120.5381,  171.1781, 2287.9858])\n",
      "tensor([  19.8778, 5469.8628,  202.7412, 6247.9634])\n",
      "tensor([2.4052e+00, 5.4839e+03, 2.6000e+02, 5.8961e+03])\n",
      "tensor([  18.9836, 7149.7090,  194.4704, 7368.9971])\n",
      "tensor([  12.1558, 6203.0298,  131.8967, 6978.2915])\n",
      "tensor([  17.7081, 4975.3794,   99.0222, 5273.7080])\n",
      "tensor([  29.6224, 6236.5225,  230.5768, 7075.0698])\n",
      "tensor([  13.6126, 6027.2456,  153.7451, 6237.3823])\n",
      "tensor([   6.6582, 4833.2095,   88.3663, 5543.1138])\n",
      "tensor([   9.8100, 5433.2227,  201.9000, 5521.0239])\n",
      "tensor([  76.7176, 3921.1843,  156.2630, 4248.6172])\n",
      "tensor([   7.2768, 5226.9453,  124.4350, 6170.1133])\n",
      "tensor([   7.8834,  411.2972,  122.3726, 1205.4879])\n",
      "tensor([1.1155e+00, 6.2964e+03, 2.6000e+02, 6.6853e+03])\n",
      "tensor([  10.2511, 1207.9458,  140.6793, 1732.2468])\n",
      "tensor([4.1400e+00, 4.8658e+03, 6.6921e+01, 5.1702e+03])\n",
      "tensor([   9.8019, 2902.5154,  129.4879, 3708.6470])\n",
      "tensor([  0.0000, 441.4967, 260.0000, 834.2288])\n",
      "tensor([  13.5551, 1838.9176,  141.2176, 2045.3009])\n",
      "tensor([  47.9101, 3981.9841,  132.9922, 4304.5830])\n",
      "tensor([   7.9572, 1339.4924,  131.6422, 2101.2349])\n",
      "tensor([  1.2397,   4.1682, 121.9637, 341.7541])\n",
      "tensor([   0.0000, 2943.3760,  256.3879, 3305.7336])\n",
      "tensor([ 154.4818, 3820.7944,  232.1096, 4038.0474])\n",
      "tensor([  18.7636, 7146.9409,  117.7157, 7447.7358])\n",
      "tensor([  25.3042, 2918.6768,  236.8584, 3730.2888])\n",
      "tensor([   9.0590, 4030.5825,  159.0360, 4255.2759])\n",
      "tensor([  16.7301,  966.6390,  152.9639, 1197.1188])\n",
      "tensor([  12.1587, 6129.0986,  156.5779, 6676.9731])\n",
      "tensor([   6.3213, 2152.6382,  180.0060, 2726.6301])\n",
      "tensor([  16.8219,  292.9384,  194.1874, 1203.2220])\n",
      "tensor([  14.5088, 3504.3440,  139.5111, 3712.7847])\n",
      "tensor([2.5815e+00, 4.8958e+03, 4.8974e+01, 5.0970e+03])\n",
      "tensor([  11.8904, 7021.4263,  233.7825, 7327.4189])\n",
      "tensor([  12.9436, 3508.6948,  138.6613, 4074.4900])\n",
      "tensor([  45.5397, 5605.9038,  136.1040, 5979.9985])\n",
      "tensor([ 133.5845, 5490.2485,  219.2554, 5962.6060])\n",
      "tensor([  25.8688, 1271.2233,  229.3783, 2092.9221])\n",
      "tensor([  12.5461, 5219.7915,  126.2771, 5422.6123])\n",
      "tensor([  15.1618, 6832.4780,  132.3543, 7370.2539])\n",
      "tensor([   4.5076, 2086.1482,  251.1190, 2438.2122])\n",
      "tensor([7.1131e+00, 6.9750e+03, 9.8902e+01, 7.4494e+03])\n",
      "tensor([   9.0994, 5313.8901,  103.2078, 5596.9927])\n",
      "tensor([   0.0000, 1268.9861,  260.0000, 1639.2991])\n",
      "tensor([1.6957e+00, 3.7693e+03, 3.1517e+01, 3.9661e+03])\n",
      "tensor([  73.1384, 1439.5513,  158.2553, 1724.9198])\n",
      "tensor([  13.8361, 6952.5342,  121.8720, 7119.1987])\n",
      "tensor([  45.7474, 3112.7222,  132.8624, 3442.5464])\n",
      "tensor([   9.9970, 4750.6304,  176.6452, 5343.6509])\n",
      "tensor([2.5582e+00, 3.8368e+03, 3.9059e+01, 4.0462e+03])\n",
      "tensor([3.8912e+00, 7.1398e+03, 7.7082e+01, 7.3525e+03])\n",
      "tensor([ 45.9113,  26.2868, 170.5164, 171.4935])\n",
      "tensor([  0.0000,   0.0000, 200.6721, 238.3439])\n",
      "tensor([  24.9669, 1410.1166,  102.4756, 1698.3712])\n",
      "tensor([   6.7929, 1990.1138,   94.3234, 2800.2212])\n",
      "tensor([ 36.9820,  41.8095, 141.5510, 269.5442])\n",
      "tensor([ 253.9342, 4683.3555,  260.0000, 5498.2954])\n",
      "tensor([   8.9577, 1995.6996,  157.4579, 2543.0100])\n",
      "tensor([   7.6707, 2801.5491,  135.0346, 3350.8318])\n",
      "tensor([  11.8330, 5334.6689,  250.8084, 5637.8320])\n",
      "tensor([2.7909e+00, 4.9778e+03, 4.5231e+01, 5.2169e+03])\n",
      "tensor([  17.5965, 3618.2168,  260.0000, 3960.8420])\n",
      "tensor([  10.3034,  810.1294,  126.6368, 1931.3245])\n",
      "tensor([   7.3011, 1156.7559,   90.3878, 1956.3556])\n",
      "tensor([2.4454e+00, 5.4052e+03, 4.4947e+01, 5.7262e+03])\n",
      "tensor([   3.3581, 2118.5298,   43.9190, 2326.2178])\n",
      "tensor([  10.1685, 5127.3340,  124.4367, 5690.6904])\n",
      "tensor([  75.5533, 5605.9756,  165.7648, 5987.7969])\n",
      "tensor([  42.2533, 1463.9065,  131.4741, 1739.8225])\n",
      "tensor([  7.1568, 272.9900, 153.7936, 837.4406])\n",
      "tensor([  10.7867, 4640.1401,  192.5833, 6156.2993])\n",
      "tensor([  20.0605, 2239.0833,   96.0516, 2580.1172])\n",
      "tensor([  12.1451, 5382.5308,  120.3970, 6901.8608])\n",
      "tensor([   7.4707, 6030.5356,   82.4209, 6909.4570])\n",
      "tensor([   9.5121, 2862.2312,  120.6243, 3061.1006])\n",
      "tensor([2.1540e+00, 3.9200e+03, 3.7090e+01, 4.1910e+03])\n",
      "tensor([3.5167e+00, 4.9912e+03, 6.0028e+01, 5.3114e+03])\n",
      "tensor([   2.5343, 1354.0375,   32.0098, 1536.5809])\n",
      "tensor([1.5881e+00, 2.9355e+03, 3.1542e+01, 3.1318e+03])\n",
      "tensor([  13.8651, 5769.6230,  148.0328, 6310.7217])\n",
      "tensor([   3.5087, 1379.1974,  260.0000, 1798.4127])\n",
      "tensor([  75.8669, 3105.0786,  162.6514, 3421.5020])\n",
      "tensor([   6.5304, 3090.1831,   82.0619, 4204.3213])\n",
      "tensor([ 157.0429, 3935.9773,  234.2363, 4307.0854])\n",
      "tensor([6.9031e-01, 3.0440e+03, 2.6000e+02, 3.4908e+03])\n",
      "tensor([  25.6717, 4993.0449,  260.0000, 5450.7036])\n",
      "tensor([  16.1845,  963.0293,  129.7275, 1526.2545])\n",
      "tensor([  12.1040, 6554.9082,  146.8903, 7122.4941])\n",
      "tensor([2.1889e+00, 6.4050e+03, 2.8651e+01, 6.6016e+03])\n",
      "tensor([ 152.1815, 3044.4644,  232.4841, 3396.6243])\n",
      "tensor([  11.6804, 3667.2581,  128.6299, 4594.1221])\n",
      "tensor([  25.5671, 5716.3350,  102.4563, 6066.1089])\n",
      "tensor([   7.6760, 2330.4470,  157.4004, 2871.2646])\n",
      "tensor([   3.3238, 2183.9717,   51.4228, 2471.6501])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nms_prediction = apply_nms(prediction, iou_thresh=0.8)\n",
    "print('NMS APPLIED MODEL OUTPUT')\n",
    "plot_img_bbox(torch_to_pil(img), nms_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take an image from the test set and try to predict on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED OUTPUT\n",
      "\n",
      "tensor([  62.0000, 3775.3442,  259.0000, 4151.7520])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAAEzCAYAAABuam47AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXqklEQVR4nO2df4xcV3XHP+e9NzP7w8naMamJDCaOQUQBKwYHEyiqIFGTkFakf1CUtBIoRErVJhVUrdqk/0ChVLRVBVSloBQMoaKENICKUJo0/Kj6T4HEJBD/xGs7bhwldmIb767XM7Mzc/rHe+ftnbezu7N+b8d39/lIT/Pmzsy7733n3nPPPed7zxVVpewSXOgb8EEugsBFEICLIAAXQQAuggBcABBE5BYROSAi4yJy36Dr7yUySDtBRELgl8BvAseAJ4E7VHXvwG6ihwy6JewAxlX1sKo2gYeA2wZ8D3Nk0CBsBJ533h9Lyi6oRBf6BrIiIncDdwMEQbB9dHQUgCiK7HNEBFWl0+lQr9ep1+uvqOrl51vnoEF4AXit8/41SVkqqvoA8ADAmjVr9G1vextBELBhwwaazSaVSoUwDGk2m4gIu3fvZvfu3Ufz3NSgu8OTwBtEZLOIVIHbge/288NmswlAEAQEQXzbrVaLTqeT+6YG2hJUtSUi9wKPAyGwU1X3LPD99DwMQzqdTloWBAHtdnvlgQCgqo8Cj/b7fdMByW+7zosSry1GF4BOp0MYhqhq2gKCIKBSqeSux2sQgK7mbi3B9EKn06Hdbueuw2sQ7KFVNVWG9h5mh8284jUI7gOLCJ1Op0s5ttvttLvkEa9BcMVVigZOq9UqREF6D4I9+MzMTNotDAA7zyveg2AShmFqKwApAKXoDqYQods2UNV0/pBXvJtAudLpdJieniaKIqanpwnDkGq1CsTdQ0QIwzB3PV6DUK/X2bVrF2EYpraBtQxVLcRQAs9BUFVmZmaYmZlZ1nq8BiEMQ9auXUulUmHNmjXpiGBTaesuJ0+ezFWP1yBUq1WuvvpqqtUqGzdupF6vU61WEREajQaNRoNjx47lBsHr0cHmCRArSddYss9W/dzBxCxEe/is5ZhXVgwINhS6c4gihkdYASCYZRhFUQpAdqjMXUfuKyyz2Hyh3W7TarXSctfrnFe8B6GXMnTLipAVAYK1BrcLmGepCPEehPkmSuZcKUI5eg8CxK2h3W7PAaM03cFaggFQ5Khg4j0I2X/bWkKRytF7EKwVuEEXaxWlGSJdc9mGx2xUKq94D4I9cBiGXdEok4GAICI7ReSEiOx2yi4TkSdE5GDyui4pFxH5x4SP9AsReavzmw8l3z8oIh9ayk26doG1COsWRUg/LeGrwC2ZsvuAH6jqG4AfJO8B3gu8ITnuBr4AMWjAx4C3E1N2PmbALSTW993wmxuHLAqIRUFQ1f8BTmWKbwMeTM4fBH7HKf+axvJjYK2IXAHcDDyhqqdU9TTwBHOBna9+gNST5A6RF9rlvkFVX0zOXwI2JOfzcZJycZXsQd14ZFZB5pHc7jVVVREpzHJxOUvmTTb/gekENyZ5IUeH40kzJ3k9kZTPx0lalKtkoqoPqOp1qnpdr6iz609wAzN55Hyv8l3ANPyHgP9wyj+YjBLXA2eSbvM4cJOIrEsU4k1JWV+SnSi5c4kigFi0O4jIN4B3A68SkWPEWv7TwMMichdwFPhA8vVHgVuBcWAauDN5iFMi8kli4hbAJ1Q1q2x7istFaLfbqcu9SGNpURBU9Y55Prqxx3cVuGee6+wEdi7p7hJxLUY3KFvULNLruAMwx0q0f76Us0jrAtYiihwdvG4JFos0y9EO+6wU3aHRaLB3717CMOS5557rMp9tqKzX67nr8RoEVWV6ehqAycnJZavHaxCCIGBkZIQgCBgeHk7jjmYnQEzWmJiYyFWP1yDUajWuvfZaoijida97HRMTE0RRRBRFnD17FoB9+/atbhCCIKBarRKGIbVajUqlQqVSQUQKI3KC50OkO/y5IXjXjC7CbPYaBJjrcreZpJnQpfA2u54lmOtTKI2jNRuHNDZbESwVWAEgwKyv0fSAWY22HiqvrAgQYJahknWmlIKzlNUFbvTJpf3nEe9BsId0w27uYhAvHK2DFptSdzqd1HDKK96DkKXnuCthXA5TrjoKucoAJMtltLJSWIzZdU9Zp0oRvCXvQbDFXlmmims55hXvQXCVX69lgaXpDibu6lh3uMwr3oNgYrReGy2KWv8EKwCEXjNFU5Qu/T+PeG8nZAlbrg4oitXqfUuwVuDOIItOIeA9CPMt+HADMXmlH+LWa0XkRyKyV0T2iMhHkvKBkbfMnebOHA2cQQ2RLeBPVfUa4HrgHhG5hgGSt7KLxYseIfohbr2oqj9LzieBfcR8o4GQt9wotNkI2fXSeWVJo4OIXAm8BfgJy0TecjlLtiRYVWk2m11eZ2OqFCF9dygRWQN8C/ioqnaFfBJyRiF35HKWwjBM0wgZhc+1EQbqVBGRCjEAX1fVbyfFx0XkClV9cQnkrXdnyv97oXobjQb79++nUqkwMTHB2bNnCYKAKIpoNpsEQcDp06f7eYSFxQ1u9DoAAb4GfDZT/vfAfcn5fcDfJee/Bfxn8rvrgZ8m5ZcBR4B1yXEEuGyRujUMw0UP4KnFnmPBevoA4V3ETf0XwDPJcSuwnnhUOAh83x4oefjPA4eAZ4HrnGt9mJjUNQ7cuVjdIqK1Wk2Hh4f1kksu0dHR0fQYGRnRkZERHRoayg3CQPMxLlWGh4f1zW9+M7VajauuuorTp0+nuZZmZmZot9scPnyY8fHxXap63fnW4/XcQUQYHh6mWq2yfv16zp07l4bmm80m7Xa7PMEXVaXRaMwZHUSEqamp3Nf3GgSzDqMoSg2kKIq6DKjStASAkZERYHYBiCSrYUozlTZmimsm24yyiFQjXitGIB0NTp061eV6t+HNTOs8siJaAsQkLusC7jS6CB7jigHBEtbCbFfodDpceumluevwHgTXtd5riXAp+AmmB6ampubohNLEIm04ND6j62HqdDqF8Bm9B8H+7aGhoa4grIFTCjvBFdeBYnqiFBaj9flz5871zKZRSB2FXGUZxY1IuyvgejHZzle8B0E1zrG0du3arriDazTlFe9BsCZvPsVsDoVSgGDRp3q93pU2wNZGlYKp4mbhc50prl7IXUfuKyyzWLMfGxtLywyQUqUsdsPwMzMzc8hbecV7EMwoajQa6UhhUlQoznsQbAQw9mpWEZaCrmNiCz3c+QOUgKnichHMs2QRatdeyCteg2CKEJhjIhdJ1/G6OzSbTY4cOZL6El555ZUUCEtjbotEc0kfAdkh4KfAz4E9wF8l5ZuJyRrjwDeBalJeS96PJ59f6Vzr/qT8AHBzH3V7E5UWYE1yXkke7HrgYeD2pPyLwB8m538EfDE5vx34ZnJ+TQJkLQHwEBAuBkIURRpFkVarVa1UKulh5VEU5Qahn3QiCljAr5IcCtwA/F5S/iDwcWKS1m3JOcAjwD9JrL1uAx5S1QZwRETGiQlc/ztf3ZbBu1KpsH37dsbHx9MwnM0ljh07xuHDhxd7jAWlX6ZKCOwCXs8s9+BXqmpLT1z+UcpN0njzqzPEXIaNwI+dyy6acCqKIi6//HKq1SqbNm3i1KlT1Go1giBIdcFLL73UzyMsKH2NDqraVtVtxBSbHcDVuWueR0TkbhF5SkSearVaacDFjCXXsXJB5g6q+ivgR8A7iKl51pLc5FEpZyn5fAw4SZ8Jp3SeZFPZRR4DTUopIpeLyNrkfJh41899xGC8P/laNuGUsVXfD/ww0SvfBW4XkZqIbCYme/50sfrtYWu1WtcDG0CD2unjCuDBRC8EwMOq+j0R2Qs8JCJ/DTwNfDn5/peBf00U3yniEQJV3SMiDwN7iVmy96jqouEjl72qqik7pahWAP0lm/oFMYEzW36YWD9ky+vA785zrU8Bn1rKDVr/t26QDcCUxqnS6XQYGRlJJ08uCKWIRUI8IkxNTRUadXLF67mDSTZrt2NRlqM72APbhGk5xHsQoNuvYK2iqLQBsEJAgNkwHHTvKFqK7mAP7O7+5QZdVr17DWbtBNtH2lWIpXG5A12LwFzfYinca65kZ43Z/Iy5rp37Csss88UZTC+UQjHaP12v19OWYF2iVOlELPyWtRFcxnseWREgQO89Y0vXHewfd19Lk2zKyBgWlXa7RFGOFe+HSOsCtlmmlRXJUfC+JZi4uiC7xUFe8R6ErFvdWoFNporYUdj77gBxK5icnJyTWsQcr3nFaxBarRbHjx9naGiI06dPc+bMmdTV3mg0ul7ziNcrZEVEzbtcqVR69v9Op8PMzMzqXSFrMtNqwQImcl6nm9eK0dKYL3s9y15DDhGRLhDevmMHURh2HUWI1yBAt30wPDy8LHV4rROyvgQ3Sl2kQl9KTpVQRJ4Wke8l7zeLyE8kzqf0TRGpJuW15P148vmVzjXuT8oPiMjNfdZ7Xp8tRZbSHT5CHJI3+VvgM6r6euA0cFdSfhdwOin/TPI9JM7NdDvwJuLUQv+cRLoXFPffd+cPUFxr6AsEEXkNca6ULyXvhZiz9EjylWyeJcu/9AhwY5azpKpHiFlsc6Lac27QmSANDw+zdevWfm55SdJvS/gs8OeAWSvr6ZOzBLicpSVtkmezR1e2bNnCpk2bCttnHvpjqvw2cEJVdxVW68L1pZylTqfTNSLY+sht27axfft21qxZU0id/YwOvw68T0RuJSZ2Xgp8joSzlPzbvThLx86XswQ8ADA0NKTZWaKqMjo6yoYNG1i7di089li/zzqv9JN77X5VfY2qXkms2H6oqr/PADhL2fBbcj/pMTQ01M8zLip57IS/YACcpaxOMHdbtVotxJdAcnPeHsPDw3rDDTfE7OMFDnLSer02m43IudzivdksIrz3llt45zvfybPPPpsaTJaacM+ePbB3b656vG4JQJpnyRaDulZiaVzuLlHL3ffFWkkpKHz2T7uc5iKjT7ACQLCHt8T22dWxpXC5u8y17EKwdrtdSMYt71uCMVQsNO9GnkqTRMJawNTU1Kxx4xC+iwjDed8dLCBrCehstHCj03nF+5aQXQdp4rLZcteR+wrLLNb/2+12SuWz8tJskGcGkctJsO5QKsUIs3aCazwVxU/wWjGqKufOnUsTUxplz6j/RXUHr6PSQRDo6OgoQRAwNjaWrop1R4hms8nExMTqjUpbSwCKWR0/j3gNQhAEaaatoaGhrv5vyvLs2bO5AfIahOHhYXbs2EEYhmzZsoXnn38+NZrq9TqNRoODBw8yPj6eqx6vQQDSh3Y31TbzuVKplCdbr0vstkmUjRilcKoAqbVo8wgzkIpywnrfHeyft+h0dgVMEeJ9SzB7oNVq9XS1FSHegwDd2ygDaSL70rQEe1B3BulOpkqRqDZrIEE3Q2VgThUReU5EnhWRZ0TkqaRsoHvDZafNQRCk+djyylKu8B5V3eZMVAayN5xNlrL93wymIvRCHhgHsjecgWDJKLN+hEH6GBX4LxHZJfHebbBMe8NlxYwk0wfZNVGDdKq8S1VfEJFfA54Qkf3uh6qqIlKIY0IyG+S5PAJLYO+azQPrDqr6QvJ6AvgOcZ8+njRzpP+94ZaUZ8kmTaYEs6NCNip1vtIPe21URC6xc+AmYDfd3KQsZ+mDyShxPXAm6TaPAzeJyLpEId6UlC1W/xwCpxuiH9TKlw3Ad5IbiYB/U9XHRORJ4GERuQs4Cnwg+f6jxHvHjQPTwJ3JzZ8SkU8CTybf+4SqnlqscjdZtWsxAoVZjf3kWToMXNuj/CRwY49yBe6Z51o7gZ1LuUFb9JUld5dqSaDbAnrlVSlCvAfBnTvYe1chliIWaQ9tRlOlUunyMBURMvAeBOh2pGS3OChCvAchOzwCqYOlNAFZd9dg6wKuciwFhQ/mz5xRlKPV+5Zgo0B20yt3Zpm7jtxXWEZxI9EzMzNdNsOFmEVeEGk0GuzZs4darcbJkyeZnp6mUql0kTmL2EPW69C8JAvGF5N2u716Q/NZIqdrHLmcxrxDpdcg1Go1tm7dShRFvPrVr05ZKwBTU1OEYcihQ4c4evRornq8BiEMQ8bGxoiiiHXr1hGGYWo222hRiqi0udOg28HihurzivcguJEn6Ha1GxB5xXsQ7KFNF2TPSwGC60hx/YpFRqa9BsF9aLcb9NIRecRrEFxKr7sZVtEGntcguOLOGSztUFHeZu9BcH0HZjm63aIU/oReJrMbqV71U2noXv9ohpOBUZq8ze66J3cBmPt5XvEeBGsFIpIu/ytd8AVmV8+7zNYsoy2PeA9C1qvsWo8D1QkislZEHhGR/SKyT0TeMSjilutiz3IUTE/klX6h/BzwmKpeTRyh3seAiFv2kNnNsLKveaQfksYY8BskOVNUtanxzmADIW5lR4JsSH5Qo8Nm4GXgKxLnXvtSwlhZFuKWOHmWbDSwkJurDK1sUIoxAt4KfEFV3wKcZbbp200qMcMtt2Q5S+mNJmQNA8LdFCuv9APCMeCYqv4kef8IMSjLQtzKistcM1Dc2WUR0k+yqZeA50XkjUnRjcS5kgZC3LI5gjX/7J5QA+EsJfLHwNclzrl4mJiMFTAA4pb7oK7J7Eaq80pfIKjqM0CvCM+yE7dg1mI0O8HVC6WZSrueJZtJFqkXvAfBnTbbCOHqiFUPQqvV4sSJE1SrVUZGRpiamkozbpkNUa/Xc9fjfVTaIkxZs9nuOyFrrN6oNHS73ZdLvAahUqmwadMmgiBg/fr16TZIkCay58SJE7z88su56vEahGq1yubNmwHYuHEj09PTKXmr1WrRbrdpNpu5QfDeqeI6U2xkMLuhiIg0eN4SYG6swZ1OlyYg644GbkadUsUdenGUoDjXGqwAEKwLWAwyy2YrRXcwcY0l15Re9fwE6HaqQLcLvlQ6IRuZttZgyWvzivcguBHobDS6FEwVoGu6bMOjuzB01U+lYZa4BbOELXdvuFIoxmzwxbqA61jJXUfuKyyzuMw1EwPDElHlFe9ByG6e65I5Z2ZmVj+t131gNwaZHTLzitcgQPfcIUvOKAVnyf5lN6mMO6vM6orzFa9BgG4LEbpd8EWJ9yCYZP/5UnGWTAn2Smrvbr2eR/phqrxR4iRTdkyIyEcHxVnq5VQZOIVPVQ9onGRqG7CdONL8HQaYbMqNSrvN/0L5GG8EDqnqUQbEWbKW4HqU3BZxIUaH24FvJOcDSTYFs5ylrPUIAzaWEoLG+4B/73GThXGWehG3gDTOkLUTBj2LfC/wM1U9nrxf9mRTYRhSr9fTxeKtVit9tWPQ/oQ7mO0KMMtZ+jRzOUv3ishDxErwjKq+KCKPA3/jKMObgPsXqrBer/P0008ThiFDQ0M9PUxFhOa7jJD5DmCUeLvDMadsPfGocBD4PnBZUi7A54FDwLPAdc5vPkzMZRoH7uyjXg3DcNGDnHvDec1PCMNQx8bG0s0y3SHRRofp6WkmJydXLz9haGiIrVu3EoYhGzZsoN1upyTOVqtFo9Fg//79TE5O5qrHa7PZ9R65ZnMURV0pCfOK1yC44m5wYVJUrqUVA4I5VIyk4Y4Qua9dwP0tq9iDmsXo5l0aJMH7gkmWkGFK0eYORYHg9ehg4v7r7qtl1cgrXrcE6E4aYRMp12pc9T5GN9pkD29doqjJE6yA7mD/tAVZ3NljUSx3r1uC+8Cu/yDrcssrXoPgKsH5dMCqB8EdIuej6RQRlfZ6Fikik8CBRb72KmBUVS8/33p8V4wHFpsii8hTqnplnkq87g6Dkosg4D8IDxT0nQXFa8U4KPG9JQxEvAVBRG4RkQMS7zx0SET2isgeEflI8vnHReQFJ1B8q/Pb+5OA8AERuXnRyvK4qpfrAEJil/1VwCbgl8A1wCXO+ceBP+vx22uAnwM14rQHh4Bwofp8bQk7gHFVPayq/wd8BbhNVSeJs3gsFMO8DXhIVRuqeoQ4xrFjocp8BaFn8FZErgTeAlgag3sTDsROJ7K15MCvryD0kgrwLeCjqjpBzHvYAmwDXgT+4Xwv7CsI2eDtJuA9wNdV9dsAqnpcVduq2gH+hdkmv/RkFRdaCc6jGCPiPA2bgSpwipj44X7nCuf8T4j1AMCb6FaMh1lEMXo5gVLVlojcS5xpYxRYB2wTkWeSr/wlcIeIbCPmRTwH/EHy2z0i8jBxto8WcI+qLjjfvmgx4q9OGKhcBIGLIAAXQQAuggBcBAG4CAJwEQQA/h+0xy8N+bTLTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## !pwd\n",
    "test_dataset = AaImagesDataset(test_dir,  setwidth, setheight, transforms= get_transform(train=True))\n",
    "# pick one image from the test set\n",
    "img, target = test_dataset[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])[0]\n",
    "    \n",
    "print('EXPECTED OUTPUT\\n')\n",
    "plot_img_bbox(torch_to_pil(img), target)\n",
    "print('MODEL OUTPUT\\n')\n",
    "nms_prediction = apply_nms(prediction, iou_thresh=0.01)\n",
    "\n",
    "plot_img_bbox(torch_to_pil(img), nms_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did predict a void even though it was a small amount of image data and a simple short training.\n",
    "\n",
    "But fear not, this is just a base line model here are some ideas we can improve it - \n",
    "1. Use a better model. \n",
    "   We have the option of changing the backbone of our model which at present is `resnet 50` and the fine tune it.\n",
    "2. We can change the training configurations like size of the images, optimizers and learning rate schedule.\n",
    "3. We can add more augmentations.\n",
    "   We have used the Albumentations library which has an extensive library of data augmentation functions. Feel free to explore and try them out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin.\n",
    "\n",
    "That's it for the notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
